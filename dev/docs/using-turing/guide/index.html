<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-language" content="en">

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Guide</title>
    <meta name="description" content="Guide">
    <meta name="author" content="The Turing Team">
    <meta name="theme-color" content="red">
    <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
    <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="canonical" href="/dev/docs/using-turing/guide/">
    <link rel="alternate" type="application/rss+xml" title="Turing.jl" href="/dev/feed.xml">
    <meta name="lang:clipboard.copy" content="Copy to clipboard">
    <meta name="lang:clipboard.copied" content="Copied to clipboard">
    <meta name="lang:search.language" content="en">
    <meta name="lang:search.pipeline.stopwords" content="True">
    <meta name="lang:search.pipeline.trimmer" content="True">
    <meta name="lang:search.result.none" content="No matching documents">
    <meta name="lang:search.result.one" content="1 matching document">
    <meta name="lang:search.result.other" content="# matching documents">
    <meta name="lang:search.tokenizer" content="[\s\-]+">
    <script src="/versions.js"></script>
    <script src="/dev/assets/js/modernizr.74668098.js"></script>
    <link rel="shortcut icon" href="/dev/assets/img/favicon.ico">
    <link rel="stylesheet" href="/dev/assets/css/main.css">
    <link rel="stylesheet" href="/dev/assets/css/palette.css">
    <link rel="stylesheet" href="/dev/assets/css/header.css">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    

    

  </head>

  <body dir="ltr" data-md-color-primary="red" data-md-color-accent="red">
    

<svg class="md-svg">
<defs>
  <svg>
  <path d="M160 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360 304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25 2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75 1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75 0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5 46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs></svg>

    <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off>
    <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off>
    <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href="#guide" tabindex=1 class=md-skip> Skip to content </a>
    <header class=md-header data-md-component=header data-md-state=none>
        <nav class="md-header-nav md-grid">
            <div class=md-flex>
                <div class="md-flex__cell md-flex__cell--shrink">
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                    <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                    <a class="md-header-nav__button md-logo" href="/dev/" title="Turing.jl">
                    <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title>
                        <span class=md-header-nav__topic>Turing.jl</span>
                    </div>
                    </a>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                  <div class="md-header-nav__source">
                    <div class="dropdown version-switch">
                      <a class="dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      </a>
                      <div class="dropdown-menu">
                        <!-- a class="dropdown-item" href="#">Stable</a -->
                        <!-- div class="dropdown-divider"></div -->
                      </div>
                    </div>
                  </div>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                  <div class="md-header-nav__source">
                    <a class="md-source" href="/dev/docs/using-turing/get-started" title="Get started">
                      Get Started
                    </a>
                  </div>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                    <div class="md-header-nav__source">
                      <a class="md-source" href="/library/" title="View Library API">
                        Library API
                      </a>
                    </div>
                  </div>

                  <div class="md-flex__cell md-flex__cell--shrink">
                      <div class="md-header-nav__source">
                        <a class="md-source" href="/dev/tutorials/" title="View tutorials">
                          Tutorials
                        </a>
                      </div>
                    </div>

                    <div class="md-flex__cell md-flex__cell--shrink">
                      <div class="md-header-nav__source">
                        <a class="md-source" href="/dev/news/" title="News">
                          News
                        </a>
                      </div>
                    </div>

                    <div class="md-flex__cell md-flex__cell--shrink">
                      <div class="md-header-nav__source">
                        <a class="md-source" href="/dev/team/" title="Team">
                          Team
                        </a>
                      </div>
                    </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                  <div class="md-header-nav__source">
                    <a class="md-source" data-md-source="github" href="https://github.com/TuringLang/Turing.jl" title="Go to repository">
                    <div class="md-source__icon" style="padding-top:5px">
                      <i class="fa fa-github fa-3x"></i>
                    </div>
                    <div class="md-source__repository">
                      TuringLang/Turing.jl
                    </div></a>
                  </div>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                  <div class="md-header-nav__source">
                    <a href="https://twitter.com/TuringLang?ref_src=twsrc%5Etfw" class="twitter-follow-button"
                       data-size="large" data-show-screen-name="false" data-show-count="false">Follow @TuringLang</a>
                    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                  </div>
                </div>

                <div class="md-flex__cell md-flex__cell--shrink">
                    <label class="md-icon md-icon--search md-header-nav__button" for=__search></label>
                    <div class=md-search data-md-component=search role=dialog>
                        <label class=md-search__overlay for=__search></label>
                        <div class=md-search__inner role=search>
                            <form class=md-search__form name=search>
                                <input type=text class=md-search__input name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active>
                                <label class="md-icon md-search__icon" for=__search></label>
                                <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button>
                            </form>
                            <div class=md-search__output>
                                <div class=md-search__scrollwrap data-md-scrollfix>
                                    <div class=md-search-result data-md-component=result>
                                        <div class=md-search-result__meta> Type to start searching </div>
                                        <ol class=md-search-result__list></ol>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
    </div>
  </nav>
</header>


    <div class="md-container">
        <main class="md-main">
            <div class="md-main__inner md-grid full-width" data-md-component="container">
            
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
  <div class="md-sidebar__scrollwrap">
    <div class="md-sidebar__inner">
      <nav class="md-nav md-nav--primary" data-md-level="0">

        <label class="md-nav__title md-nav__title--site">
            <a class="" href="/dev/" title="Turing.jl">
              <span class="md-nav__button md-logo">
                Turing.jl
              </span>
            </a>
        </label>

        <ul class="md-nav__list" data-md-scrollfix="">
          <li class="md-nav__item md-nav__item--active">
            <input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox" />

            <nav class="md-nav md-nav--secondary">

                <a class="" href="/dev/" title="Turing.jl">
                  <label class="md-nav__title md-nav__title--site">
                    <span class="md-nav__button md-logo">
                      Turing.jl
                    </span>
                  </label>
                </a>

                <div class="md-nav__source">
                    <a class="md-source" data-md-source="github" href="https://github.com/TuringLang/Turing.jl" title="Go to repository">
                    <span class="md-source__icon">
                        <i class="fa fa-github fa-3x"></i>
                    </span>
                    <span class="md-source__repository">
                      TuringLang/Turing.jl
                    </span></a>
                </div>

                <div class="md-nav__dropdown">
                  <select id="version-selector">
                    <!-- option value="#" selected="selected">v 0.5.1</option -->
                  </select>
                </div>

              <label class="md-nav__title" for="__drawer"></label>

              

                <ul class="md-nav__list" data-md-scrollfix="">
                  
                  
                  
                  <li class="md-nav__item md-nav__item--nested navbar_bottom-border">
                    <a class="md-nav__link pancakes-parent-mobile"
                    id="pancakes-using-turing" title="USING TURING">USING TURING</a>
                    
                    <nav class="md-nav md-nav--secondary">
                      <a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a>
                      <ul class="md-nav__list" data-md-scrollfix="">
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/get-started"
                              id="pancakes-getting-started"
                              title="Getting Started">Getting Started</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/quick-start"
                              id="pancakes-quick-start"
                              title="Quick Start">Quick Start</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/guide"
                              id="pancakes-guide"
                              title="Guide">Guide</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/advanced"
                              id="pancakes-advanced-usage"
                              title="Advanced Usage">Advanced Usage</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/autodiff"
                              id="pancakes-automatic-differentiation"
                              title="Automatic Differentiation">Automatic Differentiation</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/performancetips"
                              id="pancakes-performance-tips"
                              title="Performance Tips">Performance Tips</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/dynamichmc"
                              id="pancakes-using-dynamichmc"
                              title="Using DynamicHMC">Using DynamicHMC</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/sampler-viz"
                              id="pancakes-sampler-visualization"
                              title="Sampler Visualization">Sampler Visualization</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/using-turing/external-samplers"
                              id="pancakes-external-samplers"
                              title="External Samplers">External Samplers</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/library/"
                              id="pancakes-turing-api"
                              title="Turing API">Turing API</a>
                        </li>
                        
                      </ul>
                    </nav>
                    
                  </li>
                  
                  
                  <li class="md-nav__item md-nav__item--nested navbar_bottom-border">
                    <a class="md-nav__link pancakes-parent-mobile"
                    id="pancakes-for-developers" title="FOR DEVELOPERS">FOR DEVELOPERS</a>
                    
                    <nav class="md-nav md-nav--secondary">
                      <a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a>
                      <ul class="md-nav__list" data-md-scrollfix="">
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/for-developers/compiler"
                              id="pancakes-turing-compiler-design"
                              title="Turing Compiler Design">Turing Compiler Design</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/for-developers/interface"
                              id="pancakes-interface-guide"
                              title="Interface Guide">Interface Guide</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/for-developers/how_turing_implements_abstractmcmc"
                              id="pancakes-how-turing-implements-abstractmcmc"
                              title="How Turing implements AbstractMCMC">How Turing implements AbstractMCMC</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/for-developers/variational_inference"
                              id="pancakes-variational-inference"
                              title="Variational Inference">Variational Inference</a>
                        </li>
                        
                      </ul>
                    </nav>
                    
                  </li>
                  
                  
                  <li class="md-nav__item md-nav__item--nested navbar_bottom-border">
                    <a class="md-nav__link pancakes-parent-mobile"
                    id="pancakes-tutorials" title="TUTORIALS">TUTORIALS</a>
                    
                    <nav class="md-nav md-nav--secondary">
                      <a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a>
                      <ul class="md-nav__list" data-md-scrollfix="">
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials"
                              id="pancakes-home"
                              title="Home">Home</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/00-introduction"
                              id="pancakes-introduction-to-turing"
                              title="Introduction to Turing">Introduction to Turing</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/01-gaussian-mixture-model"
                              id="pancakes-gaussian-mixture-models"
                              title="Gaussian Mixture Models">Gaussian Mixture Models</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/02-logistic-regression"
                              id="pancakes-bayesian-logistic-regression"
                              title="Bayesian Logistic Regression">Bayesian Logistic Regression</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/03-bayesian-neural-network"
                              id="pancakes-bayesian-neural-networks"
                              title="Bayesian Neural Networks">Bayesian Neural Networks</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/04-hidden-markov-model"
                              id="pancakes-hidden-markov-models"
                              title="Hidden Markov Models">Hidden Markov Models</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/05-linear-regression"
                              id="pancakes-linear-regression"
                              title="Linear Regression">Linear Regression</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/06-infinite-mixture-model"
                              id="pancakes-infinite-mixture-models"
                              title="Infinite Mixture Models">Infinite Mixture Models</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/07-poisson-regression"
                              id="pancakes-bayesian-poisson-regression"
                              title="Bayesian Poisson Regression">Bayesian Poisson Regression</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/08-multinomial-logistic-regression"
                              id="pancakes-multinomial-logistic-regression"
                              title="Multinomial Logistic Regression">Multinomial Logistic Regression</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/09-variational-inference"
                              id="pancakes-variational-inference"
                              title="Variational Inference">Variational Inference</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/10-bayesian-differential-equations"
                              id="pancakes-bayesian-differential-equations"
                              title="Bayesian Differential Equations">Bayesian Differential Equations</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/11-probabilistic-pca"
                              id="pancakes-probabilistic-pca"
                              title="Probabilistic PCA">Probabilistic PCA</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/12-gplvm"
                              id="pancakes-gaussian-process-lvm"
                              title="Gaussian Process LVM">Gaussian Process LVM</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/13-seasonal-time-series"
                              id="pancakes-bayesian-time-series-analysis"
                              title="Bayesian Time Series Analysis">Bayesian Time Series Analysis</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/14-minituring"
                              id="pancakes-a-mini-turing-compiler"
                              title="A Mini Turing Compiler">A Mini Turing Compiler</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/tutorials/15-gaussian-processes"
                              id="pancakes-intro-to-gaussian-processes"
                              title="Intro to Gaussian Processes">Intro to Gaussian Processes</a>
                        </li>
                        
                      </ul>
                    </nav>
                    
                  </li>
                  
                  
                  <li class="md-nav__item md-nav__item--nested navbar_bottom-border">
                    <a class="md-nav__link pancakes-parent-mobile"
                    id="pancakes-contributing" title="CONTRIBUTING">CONTRIBUTING</a>
                    
                    <nav class="md-nav md-nav--secondary">
                      <a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a>
                      <ul class="md-nav__list" data-md-scrollfix="">
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/contributing/guide"
                              id="pancakes-how-to-contribute"
                              title="How to Contribute">How to Contribute</a>
                        </li>
                        
                        <li class="md-nav__item navbar_bottom-border">
                          <a class="md-nav__link" href="/dev/docs/contributing/style-guide"
                              id="pancakes-style-guide"
                              title="Style Guide">Style Guide</a>
                        </li>
                        
                      </ul>
                    </nav>
                    
                  </li>
                  
                </ul>
            </nav>
          </li>

          <!-- This navigation is completely for mobile -->
          <li class="md-nav__item mobile-nav" style="display:none">
            <a class="md-nav__link" title="USING TURING">USING TURING</a>
          </li><li class="md-nav__item mobile-nav" style="display:none">
            <a class="md-nav__link" title="FOR DEVELOPERS">FOR DEVELOPERS</a>
          </li><li class="md-nav__item mobile-nav" style="display:none">
            <a class="md-nav__link" title="TUTORIALS">TUTORIALS</a>
          </li><li class="md-nav__item mobile-nav" style="display:none">
            <a class="md-nav__link" title="CONTRIBUTING">CONTRIBUTING</a>
          </li>

          <!-- This navigation is completely for non mobile -->
          

         
         
         <li class="md-nav__item md-nav__item--nested not-mobile-nav invisible">
             <a class="md-nav__link pancakes-parent open-parent"
                id="pancakes-using-turing"
                title="USING TURING">USING TURING</a>
                
                <nav class="md-nav">
                    <ul class="md-nav__list">
                        
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/get-started"
                           title="Getting Started" 
                           
                           class="md-nav__link pancakes-child">Getting Started</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/quick-start"
                           title="Quick Start" 
                           
                           class="md-nav__link pancakes-child">Quick Start</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/guide"
                           title="Guide" 
                            style="color: red;"
                           class="md-nav__link pancakes-child">Guide</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/advanced"
                           title="Advanced Usage" 
                           
                           class="md-nav__link pancakes-child">Advanced Usage</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/autodiff"
                           title="Automatic Differentiation" 
                           
                           class="md-nav__link pancakes-child">Automatic Differentiation</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/performancetips"
                           title="Performance Tips" 
                           
                           class="md-nav__link pancakes-child">Performance Tips</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/dynamichmc"
                           title="Using DynamicHMC" 
                           
                           class="md-nav__link pancakes-child">Using DynamicHMC</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/sampler-viz"
                           title="Sampler Visualization" 
                           
                           class="md-nav__link pancakes-child">Sampler Visualization</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/using-turing/external-samplers"
                           title="External Samplers" 
                           
                           class="md-nav__link pancakes-child">External Samplers</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/library/"
                           title="Turing API" 
                           
                           class="md-nav__link pancakes-child">Turing API</a>
                        </li>
                    </ul>
                </nav>
                
         </li>
         
         
         <li class="md-nav__item md-nav__item--nested not-mobile-nav invisible">
             <a class="md-nav__link pancakes-parent "
                id="pancakes-for-developers"
                title="FOR DEVELOPERS">FOR DEVELOPERS</a>
                
                <nav class="md-nav">
                    <ul class="md-nav__list">
                        
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/for-developers/compiler"
                           title="Turing Compiler Design" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Turing Compiler Design</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/for-developers/interface"
                           title="Interface Guide" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Interface Guide</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/for-developers/how_turing_implements_abstractmcmc"
                           title="How Turing implements AbstractMCMC" style="display:none;"
                           
                           class="md-nav__link pancakes-child">How Turing implements AbstractMCMC</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/for-developers/variational_inference"
                           title="Variational Inference" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Variational Inference</a>
                        </li>
                    </ul>
                </nav>
                
         </li>
         
         
         <li class="md-nav__item md-nav__item--nested not-mobile-nav invisible">
             <a class="md-nav__link pancakes-parent "
                id="pancakes-tutorials"
                title="TUTORIALS">TUTORIALS</a>
                
                <nav class="md-nav">
                    <ul class="md-nav__list">
                        
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials"
                           title="Home" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Home</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/00-introduction"
                           title="Introduction to Turing" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Introduction to Turing</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/01-gaussian-mixture-model"
                           title="Gaussian Mixture Models" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Gaussian Mixture Models</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/02-logistic-regression"
                           title="Bayesian Logistic Regression" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Bayesian Logistic Regression</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/03-bayesian-neural-network"
                           title="Bayesian Neural Networks" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Bayesian Neural Networks</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/04-hidden-markov-model"
                           title="Hidden Markov Models" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Hidden Markov Models</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/05-linear-regression"
                           title="Linear Regression" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Linear Regression</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/06-infinite-mixture-model"
                           title="Infinite Mixture Models" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Infinite Mixture Models</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/07-poisson-regression"
                           title="Bayesian Poisson Regression" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Bayesian Poisson Regression</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/08-multinomial-logistic-regression"
                           title="Multinomial Logistic Regression" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Multinomial Logistic Regression</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/09-variational-inference"
                           title="Variational Inference" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Variational Inference</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/10-bayesian-differential-equations"
                           title="Bayesian Differential Equations" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Bayesian Differential Equations</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/11-probabilistic-pca"
                           title="Probabilistic PCA" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Probabilistic PCA</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/12-gplvm"
                           title="Gaussian Process LVM" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Gaussian Process LVM</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/13-seasonal-time-series"
                           title="Bayesian Time Series Analysis" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Bayesian Time Series Analysis</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/14-minituring"
                           title="A Mini Turing Compiler" style="display:none;"
                           
                           class="md-nav__link pancakes-child">A Mini Turing Compiler</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/tutorials/15-gaussian-processes"
                           title="Intro to Gaussian Processes" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Intro to Gaussian Processes</a>
                        </li>
                    </ul>
                </nav>
                
         </li>
         
         
         <li class="md-nav__item md-nav__item--nested not-mobile-nav invisible">
             <a class="md-nav__link pancakes-parent "
                id="pancakes-contributing"
                title="CONTRIBUTING">CONTRIBUTING</a>
                
                <nav class="md-nav">
                    <ul class="md-nav__list">
                        
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/contributing/guide"
                           title="How to Contribute" style="display:none;"
                            style="color: red;"
                           class="md-nav__link pancakes-child">How to Contribute</a>
                        </li>
                        
                        <li class="md-nav__item">
                        <a href="/dev/docs/contributing/style-guide"
                           title="Style Guide" style="display:none;"
                           
                           class="md-nav__link pancakes-child">Style Guide</a>
                        </li>
                    </ul>
                </nav>
                
         </li>
         
         

        </ul>
      </nav>
    </div>
  </div>
</div>


<div class="md-sidebar md-sidebar--secondary invisible" data-md-component="toc">
  <div class="md-sidebar__scrollwrap">
    <div class="md-sidebar__inner">
      <nav class="md-nav md-nav--secondary">
        <label class="md-nav__title" for="__toc">Table of contents</label>
        <ul id="nav-toc" class="md-nav__list" data-md-scrollfix="">
        <!-- toc will be appended here!-->
        </ul>
        <a href="https://twitter.com/intent/tweet?original_referer=https://github.com/TuringLang/Turing.jl/edit/master/docs/src_tutorials/using-turing-guide.md" title="Tweet this page" class="social-link"><i class="fa fa-twitter fa-1x"></i>Tweet this page</a>
        <a href="https://discourse.julialang.org/c/domain/probprog" title="Ask questions" class="social-link"><i class="fa fa-stack-overflow fa-1x"></i>Ask questions</a>
        <a href="https://github.com/TuringLang/Turing.jl//issues/new?label=question&title=Question:&body=Question%20on:%20https://github.com/TuringLang/Turing.jl/edit/master/docs/_tutorials/using-turing-guide.md" title="Report issues" class="social-link"><i class="fa fa-comments fa-1x"></i>Report issues</a>
        <a href="https://github.com/TuringLang/Turing.jl/edit/master/docs/src_tutorials/using-turing-guide.md" title="Edit this page on github"  class="social-link"><i class="fa fa-github fa-1x"></i> Edit me</a>
      </nav>
    </div>
  </div>
</div>

                <div id="md-container-pancakes">
                <div class="md-content full-width"> 
    <article class="md-content__inner md-typeset  full-width">
    <h1 id="guide">Guide</h1>
<h2 id="basics">Basics</h2>
<h3 id="introduction">Introduction</h3>
<p>A probabilistic program is Julia code wrapped in a <code>@model</code> macro. It can use arbitrary Julia code, but to ensure correctness of inference it should not have external effects or modify global state. Stack-allocated variables are safe, but mutable heap-allocated objects may lead to subtle bugs when using task copying. By default Libtask deepcopies <code>Array</code> and <code>Dict</code> objects when copying task to avoid bugs with data stored in mutable structure in Turing models.</p>
<p>To specify distributions of random variables, Turing programs should use the <code>~</code> notation:</p>
<p><code>x ~ distr</code> where <code>x</code> is a symbol and <code>distr</code> is a distribution. If <code>x</code> is undefined in the model function, inside the probabilistic program, this puts a random variable named <code>x</code>, distributed according to <code>distr</code>, in the current scope. <code>distr</code> can be a value of any type that implements <code>rand(distr)</code>, which samples a value from the distribution <code>distr</code>. If <code>x</code> is defined, this is used for conditioning in a style similar to <a href="https://probprog.github.io/anglican/index.html">Anglican</a> (another PPL). In this case, <code>x</code> is an observed value, assumed to have been drawn from the distribution <code>distr</code>. The likelihood is computed using <code>logpdf(distr,y)</code>. The observe statements should be arranged so that every possible run traverses all of them in exactly the same order. This is equivalent to demanding that they are not placed inside stochastic control flow.</p>
<p>Available inference methods include Importance Sampling (IS), Sequential Monte Carlo (SMC), Particle Gibbs (PG), Hamiltonian Monte Carlo (HMC), Hamiltonian Monte Carlo with Dual Averaging (HMCDA) and The No-U-Turn Sampler (NUTS).</p>
<h3 id="simple-gaussian-demo">Simple Gaussian Demo</h3>
<p>Below is a simple Gaussian demo illustrate the basic usage of Turing.jl.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import packages.</span>
<span class="k">using</span> <span class="n">Turing</span>
<span class="k">using</span> <span class="n">StatsPlots</span>

<span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">return</span> <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>gdemo (generic function with 2 methods)
</code></pre>
<p>Note: As a sanity check, the prior expectation of <code>s²</code> is <code>mean(InverseGamma(2, 3)) = 3/(2 - 1) = 3</code> and the prior expectation of <code>m</code> is 0. This can be easily checked using <code>Prior</code>:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p1</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="nb">missing</span><span class="x">,</span> <span class="nb">missing</span><span class="x">),</span> <span class="n">Prior</span><span class="x">(),</span> <span class="mi">100000</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (100000×5×1 Array{Float64, 3}):

Iterations        = 1:1:100000
Number of chains  = 1
Samples per chain = 100000
Wall duration     = 2.1 seconds
Compute duration  = 2.1 seconds
parameters        = s², m, x, y
internals         = lp

Summary Statistics
  parameters      mean       std      mcse      ess_bulk     ess_tail      
rha ⋯
      Symbol   Float64   Float64   Float64       Float64      Float64   Flo
at6 ⋯

          s²    2.9424    5.6793    0.0180   100347.7019   99440.6204    1.
000 ⋯
           m    0.0003    1.7101    0.0054    99890.2582   98065.6160    1.
000 ⋯
           x    0.0139    2.4361    0.0077    99755.2179   98064.8845    1.
000 ⋯
           y   -0.0063    2.4221    0.0077    99001.9384   98925.3975    1.
000 ⋯
                                                               2 columns om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

          s²    0.5381    1.1138    1.7825    3.1037   12.1347
           m   -3.3473   -0.9125   -0.0049    0.9035    3.3792
           x   -4.7745   -1.2786    0.0120    1.2816    4.8070
           y   -4.7919   -1.2892   -0.0003    1.2713    4.7882
</code></pre>
<p>We can perform inference by using the <code>sample</code> function, the first argument of which is our probabilistic program and the second of which is a sampler. More information on each sampler is located in the <a href="%7B%7Bsite.baseurl%7D%7D/docs/library">API</a>.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#  Run sampler, collect results.</span>
<span class="n">c1</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(),</span> <span class="mi">1000</span><span class="x">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">PG</span><span class="x">(</span><span class="mi">10</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
<span class="n">c4</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">Gibbs</span><span class="x">(</span><span class="n">PG</span><span class="x">(</span><span class="mi">10</span><span class="x">,</span> <span class="o">:</span><span class="n">m</span><span class="x">),</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">,</span> <span class="o">:</span><span class="n">s²</span><span class="x">)),</span> <span class="mi">1000</span><span class="x">)</span>
<span class="n">c5</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">HMCDA</span><span class="x">(</span><span class="mf">0.15</span><span class="x">,</span> <span class="mf">0.65</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
<span class="n">c6</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">NUTS</span><span class="x">(</span><span class="mf">0.65</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (1000×14×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 2.06 seconds
Compute duration  = 2.06 seconds
parameters        = s², m
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, h
amiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, 
tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

          s²    1.9289    1.4467    0.0604   565.2070   633.2511    1.0015 
    ⋯
           m    1.1824    0.7217    0.0298   585.7603   655.4807    1.0000 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

          s²    0.5766    1.0328    1.5063    2.3328    5.8806
           m   -0.2834    0.6983    1.1991    1.6599    2.5946
</code></pre>
<p>The <code>MCMCChains</code> module (which is re-exported by Turing) provides plotting tools for the <code>Chain</code> objects returned by a <code>sample</code> function. See the <a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains</a> repository for more information on the suite of tools available for diagnosing MCMC chains.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Summarise results</span>
<span class="n">describe</span><span class="x">(</span><span class="n">c3</span><span class="x">)</span>

<span class="c"># Plot results</span>
<span class="n">plot</span><span class="x">(</span><span class="n">c3</span><span class="x">)</span>
<span class="n">savefig</span><span class="x">(</span><span class="s">"gdemo-plot.png"</span><span class="x">)</span>
</code></pre></div></div>
<p>The arguments for each sampler are:</p>
<ul>
<li>SMC: number of particles.</li>
<li>PG: number of particles, number of iterations.</li>
<li>HMC: leapfrog step size, leapfrog step numbers.</li>
<li>Gibbs: component sampler 1, component sampler 2, ...</li>
<li>HMCDA: total leapfrog length, target accept ratio.</li>
<li>NUTS: number of adaptation steps (optional), target accept ratio.</li>
</ul>
<p>For detailed information on the samplers, please review Turing.jl's <a href="%7B%7Bsite.baseurl%7D%7D/docs/library">API</a> documentation.</p>
<h3 id="modelling-syntax-explained">Modelling Syntax Explained</h3>
<p>Using this syntax, a probabilistic model is defined in Turing. The model function generated by Turing can then be used to condition the model onto data. Subsequently, the sample function can be used to generate samples from the posterior distribution.</p>
<p>In the following example, the defined model is conditioned to the data (arg<em>1 = 1, arg</em>2 = 2) by passing (1, 2) to the model function.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> model_name</span><span class="x">(</span><span class="n">arg_1</span><span class="x">,</span> <span class="n">arg_2</span><span class="x">)</span>
    <span class="k">return</span> <span class="o">...</span>
<span class="k">end</span>
</code></pre></div></div>
<p>The conditioned model can then be passed onto the sample function to run posterior inference.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_func</span> <span class="o">=</span> <span class="n">model_name</span><span class="x">(</span><span class="mi">1</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
<span class="n">chn</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model_func</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="o">..</span><span class="x">))</span> <span class="c"># Perform inference by sampling using HMC.</span>
</code></pre></div></div>
<p>The returned chain contains samples of the variables in the model.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">var_1</span> <span class="o">=</span> <span class="n">mean</span><span class="x">(</span><span class="n">chn</span><span class="x">[</span><span class="o">:</span><span class="n">var_1</span><span class="x">])</span> <span class="c"># Taking the mean of a variable named var_1.</span>
</code></pre></div></div>
<p>The key (<code>:var_1</code>) can be a <code>Symbol</code> or a <code>String</code>. For example, to fetch <code>x[1]</code>, one can use <code>chn[Symbol(&quot;x[1]&quot;)]</code> or <code>chn[&quot;x[1]&quot;]</code>.
If you want to retrieve all parameters associated with a specific symbol, you can use <code>group</code>. As an example, if you have the
parameters <code>&quot;x[1]&quot;</code>, <code>&quot;x[2]&quot;</code>, and <code>&quot;x[3]&quot;</code>, calling <code>group(chn, :x)</code> or <code>group(chn, &quot;x&quot;)</code> will return a new chain with only <code>&quot;x[1]&quot;</code>, <code>&quot;x[2]&quot;</code>, and <code>&quot;x[3]&quot;</code>.</p>
<p>Turing does not have a declarative form. More generally, the order in which you place the lines of a <code>@model</code> macro matters. For example, the following example works:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="k">function</span><span class="nf"> model_function</span><span class="x">(</span><span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">Poisson</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">s</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">y</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">model_function</span><span class="x">(</span><span class="mi">10</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(),</span> <span class="mi">100</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (100×3×1 Array{Float64, 3}):

Log evidence      = -22.4209907336435
Iterations        = 1:1:100
Number of chains  = 1
Samples per chain = 100
Wall duration     = 1.84 seconds
Compute duration  = 1.84 seconds
parameters        = s
internals         = lp, weight

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

           s    4.0000    0.0000       NaN        NaN        NaN       NaN 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           s    4.0000    4.0000    4.0000    4.0000    4.0000
</code></pre>
<p>But if we switch the <code>s ~ Poisson(1)</code> and <code>y ~ Normal(s, 1)</code> lines, the model will no longer sample correctly:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="k">function</span><span class="nf"> model_function</span><span class="x">(</span><span class="n">y</span><span class="x">)</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">s</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">Poisson</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">y</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">model_function</span><span class="x">(</span><span class="mi">10</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(),</span> <span class="mi">100</span><span class="x">)</span>
</code></pre></div></div>
<h3 id="sampling-multiple-chains">Sampling Multiple Chains</h3>
<p>Turing supports distributed and threaded parallel sampling. To do so, call <code>sample(model, sampler, parallel_type, n, n_chains)</code>, where <code>parallel_type</code> can be either <code>MCMCThreads()</code> or <code>MCMCDistributed()</code> for thread and parallel sampling, respectively.</p>
<p>Having multiple chains in the same object is valuable for evaluating convergence. Some diagnostic functions like <code>gelmandiag</code> require multiple chains.</p>
<p>If you do not want parallelism or are on an older version Julia, you can sample multiple chains with the <code>mapreduce</code> function:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Replace num_chains below with however many chains you wish to sample.</span>
<span class="n">chains</span> <span class="o">=</span> <span class="n">mapreduce</span><span class="x">(</span><span class="n">c</span> <span class="o">-&gt;</span> <span class="n">sample</span><span class="x">(</span><span class="n">model_fun</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="mi">1000</span><span class="x">),</span> <span class="n">chainscat</span><span class="x">,</span> <span class="mi">1</span><span class="o">:</span><span class="n">num_chains</span><span class="x">)</span>
</code></pre></div></div>
<p>The <code>chains</code> variable now contains a <code>Chains</code> object which can be indexed by chain. To pull out the first chain from the <code>chains</code> object, use <code>chains[:,:,1]</code>. The method is the same if you use either of the below parallel sampling methods.</p>
<h4 id="multithreaded-sampling">Multithreaded sampling</h4>
<p>If you wish to perform multithreaded sampling and are running Julia 1.3 or greater, you can call <code>sample</code> with the following signature:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Turing</span>

<span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">])</span>

<span class="c"># Sample four chains using multiple threads, each with 1000 samples.</span>
<span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">NUTS</span><span class="x">(),</span> <span class="n">MCMCThreads</span><span class="x">(),</span> <span class="mi">1000</span><span class="x">,</span> <span class="mi">4</span><span class="x">)</span>
</code></pre></div></div>
<p>Be aware that Turing cannot add threads for you -- you must have started your Julia instance with multiple threads to experience any kind of parallelism. See the <a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#man-multithreading-1">Julia documentation</a> for details on how to achieve this.</p>
<h4 id="distributed-sampling">Distributed sampling</h4>
<p>To perform distributed sampling (using multiple processes), you must first import <code>Distributed</code>.</p>
<p>Process parallel sampling can be done like so:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Load Distributed to add processes and the @everywhere macro.</span>
<span class="k">using</span> <span class="n">Distributed</span>

<span class="c"># Load Turing.</span>
<span class="k">using</span> <span class="n">Turing</span>

<span class="c"># Add four processes to use for sampling.</span>
<span class="n">addprocs</span><span class="x">(</span><span class="mi">4</span><span class="x">;</span> <span class="n">exeflags</span><span class="o">=</span><span class="s">"--project=</span><span class="si">$</span><span class="s">(Base.active_project())"</span><span class="x">)</span>

<span class="c"># Initialize everything on all the processes.</span>
<span class="c"># Note: Make sure to do this after you've already loaded Turing,</span>
<span class="c">#       so each process does not have to precompile.</span>
<span class="c">#       Parallel sampling may fail silently if you do not do this.</span>
<span class="nd">@everywhere</span> <span class="k">using</span> <span class="n">Turing</span>

<span class="c"># Define a model on all processes.</span>
<span class="nd">@everywhere</span> <span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># Declare the model instance everywhere.</span>
<span class="nd">@everywhere</span> <span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">])</span>

<span class="c"># Sample four chains using multiple processes, each with 1000 samples.</span>
<span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">NUTS</span><span class="x">(),</span> <span class="n">MCMCDistributed</span><span class="x">(),</span> <span class="mi">1000</span><span class="x">,</span> <span class="mi">4</span><span class="x">)</span>
</code></pre></div></div>
<h3 id="sampling-from-an-unconditional-distribution-the-prior">Sampling from an Unconditional Distribution (The Prior)</h3>
<p>Turing allows you to sample from a declared model's prior. If you wish to draw a chain from the prior to inspect your prior distributions, you can simply run</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">Prior</span><span class="x">(),</span> <span class="n">n_samples</span><span class="x">)</span>
</code></pre></div></div>
<p>You can also run your model (as if it were a function) from the prior distribution, by calling the model without specifying inputs or a sampler. In the below example, we specify a <code>gdemo</code> model which returns two variables, <code>x</code> and <code>y</code>. The model includes <code>x</code> and <code>y</code> as arguments, but calling the function without passing in <code>x</code> or <code>y</code> means that Turing's compiler will assume they are missing values to draw from the relevant distribution. The <code>return</code> statement is necessary to retrieve the sampled <code>x</code> and <code>y</code> values.
Assign the function with <code>missing</code> inputs to a variable, and Turing will produce a sample from the prior distribution.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">return</span> <span class="n">x</span><span class="x">,</span> <span class="n">y</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>gdemo (generic function with 2 methods)
</code></pre>
<p>Assign the function with <code>missing</code> inputs to a variable, and Turing will produce a sample from the prior distribution.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Samples from p(x,y)</span>
<span class="n">g_prior_sample</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">(</span><span class="nb">missing</span><span class="x">,</span> <span class="nb">missing</span><span class="x">)</span>
<span class="n">g_prior_sample</span><span class="x">()</span>
</code></pre></div></div>
<pre><code>(0.1741213188090317, -0.5141306911530534)
</code></pre>
<h3 id="sampling-from-a-conditional-distribution-the-posterior">Sampling from a Conditional Distribution (The Posterior)</h3>
<h4 id="treating-observations-as-random-variables">Treating observations as random variables</h4>
<p>Inputs to the model that have a value <code>missing</code> are treated as parameters, aka random variables, to be estimated/sampled. This can be useful if you want to simulate draws for that parameter, or if you are sampling from a conditional distribution. Turing supports the following syntax:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="o">::</span><span class="kt">Type</span><span class="x">{</span><span class="n">T</span><span class="x">}</span><span class="o">=</span><span class="kt">Float64</span><span class="x">)</span> <span class="k">where</span> <span class="x">{</span><span class="n">T</span><span class="x">}</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">===</span> <span class="nb">missing</span>
        <span class="c"># Initialize `x` if missing</span>
        <span class="n">x</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="nb">undef</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># Construct a model with x = missing</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">(</span><span class="nb">missing</span><span class="x">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">500</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (500×14×1 Array{Float64, 3}):

Iterations        = 1:1:500
Number of chains  = 1
Samples per chain = 500
Wall duration     = 1.86 seconds
Compute duration  = 1.86 seconds
parameters        = s², m, x[1], x[2]
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, h
amiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, no
m_step_size

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

          s²    0.7271    0.2249    0.0842     7.6115    10.8946    1.0866 
    ⋯
           m   -0.2311    0.2300    0.0543    18.7223    38.4238    1.0040 
    ⋯
        x[1]   -0.0177    0.3176    0.2204     2.1975    27.9147    1.3983 
    ⋯
        x[2]   -0.6931    0.2532    0.0768    11.8370    28.3523    1.0758 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

          s²    0.2867    0.5873    0.7466    0.8790    1.1814
           m   -0.6826   -0.4042   -0.2247   -0.0424    0.1559
        x[1]   -0.5122   -0.2953   -0.0706    0.2731    0.4980
        x[2]   -1.1639   -0.8739   -0.6643   -0.4794   -0.2824
</code></pre>
<p>Note the need to initialize <code>x</code> when missing since we are iterating over its elements later in the model. The generated values for <code>x</code> can be extracted from the <code>Chains</code> object using <code>c[:x]</code>.</p>
<p>Turing also supports mixed <code>missing</code> and non-<code>missing</code> values in <code>x</code>, where the missing ones will be treated as random variables to be sampled while the others get treated as observations. For example:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># x[1] is a parameter, but x[2] is an observation</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">([</span><span class="nb">missing</span><span class="x">,</span> <span class="mf">2.4</span><span class="x">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">500</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (500×13×1 Array{Float64, 3}):

Iterations        = 1:1:500
Number of chains  = 1
Samples per chain = 500
Wall duration     = 1.87 seconds
Compute duration  = 1.87 seconds
parameters        = s², m, x[1]
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, h
amiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, no
m_step_size

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

          s²    3.1704    1.7342    1.4214     1.5735    11.1270    1.7116 
    ⋯
           m   -0.5925    0.4070    0.3487     1.4041    17.9775    1.9386 
    ⋯
        x[1]   -1.4030    0.6071    0.5276     1.4381    22.5542    1.9377 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

          s²    0.7774    1.4557    3.1170    4.4699    6.6135
           m   -1.2511   -0.9028   -0.6544   -0.3092    0.2459
        x[1]   -2.4749   -1.8908   -1.2775   -0.9157   -0.5026
</code></pre>
<h4 id="default-values">Default Values</h4>
<p>Arguments to Turing models can have default values much like how default values work in normal Julia functions. For instance, the following will assign <code>missing</code> to <code>x</code> and treat it as a random variable. If the default value is not <code>missing</code>, <code>x</code> will be assigned that value and will be treated as an observation instead.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Turing</span>

<span class="nd">@model</span> <span class="k">function</span><span class="nf"> generative</span><span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="nb">missing</span><span class="x">,</span> <span class="o">::</span><span class="kt">Type</span><span class="x">{</span><span class="n">T</span><span class="x">}</span><span class="o">=</span><span class="kt">Float64</span><span class="x">)</span> <span class="k">where</span> <span class="x">{</span><span class="n">T</span><span class="o">&lt;:</span><span class="kt">Real</span><span class="x">}</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">===</span> <span class="nb">missing</span>
        <span class="c"># Initialize x when missing</span>
        <span class="n">x</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="nb">undef</span><span class="x">,</span> <span class="mi">10</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">s²</span><span class="x">,</span> <span class="n">m</span>
<span class="k">end</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">generative</span><span class="x">()</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (1000×22×1 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 3.48 seconds
Compute duration  = 3.48 seconds
parameters        = s², m, x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], 
x[9], x[10]
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, h
amiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, no
m_step_size

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

          s²    1.1119    0.5207    0.2842     3.1801    21.1090    1.4925 
    ⋯
           m    0.7230    0.3327    0.1126     9.5545    20.4148    1.0748 
    ⋯
        x[1]    1.1839    0.5516    0.3449     2.8437    21.5142    1.8318 
    ⋯
        x[2]   -0.0426    1.1914    0.7555     2.5746    14.5364    2.0000 
    ⋯
        x[3]    2.2109    0.4282    0.2460     3.3195    21.2188    1.4879 
    ⋯
        x[4]    0.7597    0.2948    0.1332     5.3609    38.9687    1.1695 
    ⋯
        x[5]    0.1832    0.4150    0.1246    11.7747    18.1758    1.0769 
    ⋯
        x[6]    0.1954    0.4584    0.2712     2.9072    20.2899    1.8015 
    ⋯
        x[7]    1.1014    0.2734    0.0862    10.2761    33.9279    1.0363 
    ⋯
        x[8]    0.8650    0.7467    0.4947     2.6025    24.3852    2.1000 
    ⋯
        x[9]    0.7267    0.3944    0.1444     7.4158    15.8452    1.0546 
    ⋯
       x[10]    0.9286    0.3653    0.1516     5.9118    21.5974    1.2243 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

          s²    0.4383    0.7739    1.0078    1.3546    2.6791
           m    0.0607    0.4999    0.7738    0.9723    1.2585
        x[1]    0.3118    0.7075    1.1020    1.7223    2.0737
        x[2]   -1.5459   -0.8948   -0.6965    1.3969    2.2193
        x[3]    1.4374    1.8335    2.2466    2.6105    2.8625
        x[4]    0.2627    0.5428    0.7215    0.9632    1.3350
        x[5]   -0.4876   -0.1422    0.1458    0.4749    1.0366
        x[6]   -0.4925   -0.1268    0.0906    0.4979    1.1674
        x[7]    0.5612    0.9157    1.0847    1.2993    1.6003
        x[8]   -0.1609    0.1762    0.6902    1.5329    2.0586
        x[9]    0.0375    0.3880    0.7529    1.0318    1.5096
       x[10]    0.1622    0.6578    0.9234    1.2332    1.5525
</code></pre>
<h4 id="access-values-inside-chain">Access Values inside Chain</h4>
<p>You can access the values inside a chain several ways:</p>
<ol>
<li>Turn them into a <code>DataFrame</code> object</li>
<li>Use their raw <code>AxisArray</code> form</li>
<li>Create a three-dimensional <code>Array</code> object</li>
</ol>
<p>For example, let <code>c</code> be a <code>Chain</code>:</p>
<ol>
<li><code>DataFrame(c)</code> converts <code>c</code> to a <code>DataFrame</code>,</li>
<li><code>c.value</code> retrieves the values inside <code>c</code> as an <code>AxisArray</code>, and</li>
<li><code>c.value.data</code> retrieves the values inside <code>c</code> as a 3D <code>Array</code>.</li>
</ol>
<h4 id="variable-types-and-type-parameters">Variable Types and Type Parameters</h4>
<p>The element type of a vector (or matrix) of random variables should match the <code>eltype</code> of the its prior distribution, <code>&lt;: Integer</code> for discrete distributions and <code>&lt;: AbstractFloat</code> for continuous distributions. Moreover, if the continuous random variable is to be sampled using a Hamiltonian sampler, the vector's element type needs to either be:</p>
<ol>
<li><code>Real</code> to enable auto-differentiation through the model which uses special number types that are sub-types of <code>Real</code>, or</li>
<li>Some type parameter <code>T</code> defined in the model header using the type parameter syntax, e.g. <code>function gdemo(x, ::Type{T} = Float64) where {T}</code>.
Similarly, when using a particle sampler, the Julia variable used should either be:</li>
<li>An <code>Array</code>, or</li>
<li>An instance of some type parameter <code>T</code> defined in the model header using the type parameter syntax, e.g. <code>function gdemo(x, ::Type{T} = Vector{Float64}) where {T}</code>.</li>
</ol>
<h3 id="querying-probabilities-from-model-or-chain">Querying Probabilities from Model or Chain</h3>
<p>Turing offers three functions: <a href="https://turinglang.org/DynamicPPL.jl/dev/api/#StatsAPI.loglikelihood"><code>loglikelihood</code></a>, <a href="https://turinglang.org/DynamicPPL.jl/dev/api/#DynamicPPL.logprior"><code>logprior</code></a>, and <a href="https://turinglang.org/DynamicPPL.jl/dev/api/#DynamicPPL.logjoint"><code>logjoint</code></a> to query the log-likelihood, log-prior, and log-joint probabilities of a model, respectively.</p>
<p>Let's look at a simple model called <code>gdemo</code>:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo0</span><span class="x">()</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>gdemo0 (generic function with 2 methods)
</code></pre>
<p>If we observe x to be 1.0, we can condition the model on this datum using the <a href="https://turinglang.org/DynamicPPL.jl/dev/api/#AbstractPPL.condition"><code>condition</code></a> syntax:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">gdemo0</span><span class="x">()</span> <span class="o">|</span> <span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="mf">1.0</span><span class="x">,)</span>
</code></pre></div></div>
<pre><code>DynamicPPL.Model{typeof(Main.var&quot;##WeaveSandBox#413&quot;.gdemo0), (), (), (), T
uple{}, Tuple{}, DynamicPPL.ConditionContext{@NamedTuple{x::Float64}, Dynam
icPPL.DefaultContext}}(Main.var&quot;##WeaveSandBox#413&quot;.gdemo0, NamedTuple(), N
amedTuple(), ConditionContext((x = 1.0,), DynamicPPL.DefaultContext()))
</code></pre>
<p>Now, let's compute the log-likelihood of the observation given specific values of the model parameters, <code>s</code> and <code>m</code>:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loglikelihood</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="x">(</span><span class="n">s</span><span class="o">=</span><span class="mf">1.0</span><span class="x">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">1.0</span><span class="x">))</span>
</code></pre></div></div>
<pre><code>-0.9189385332046728
</code></pre>
<p>We can easily verify that value in this case:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logpdf</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">),</span> <span class="mf">1.0</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>-0.9189385332046728
</code></pre>
<p>We can also compute the log-prior probability of the model for the same values of s and m:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logprior</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="x">(</span><span class="n">s</span><span class="o">=</span><span class="mf">1.0</span><span class="x">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">1.0</span><span class="x">))</span>
</code></pre></div></div>
<pre><code>-2.221713955868453
</code></pre>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logpdf</span><span class="x">(</span><span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">),</span> <span class="mf">1.0</span><span class="x">)</span> <span class="o">+</span> <span class="n">logpdf</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="mf">1.0</span><span class="x">)),</span> <span class="mf">1.0</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>-2.221713955868453
</code></pre>
<p>Finally, we can compute the log-joint probability of the model parameters and data:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logjoint</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="x">(</span><span class="n">s</span><span class="o">=</span><span class="mf">1.0</span><span class="x">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">1.0</span><span class="x">))</span>
</code></pre></div></div>
<pre><code>-3.1406524890731258
</code></pre>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logpdf</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">),</span> <span class="mf">1.0</span><span class="x">)</span> <span class="o">+</span>
<span class="n">logpdf</span><span class="x">(</span><span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">),</span> <span class="mf">1.0</span><span class="x">)</span> <span class="o">+</span>
<span class="n">logpdf</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="mf">1.0</span><span class="x">)),</span> <span class="mf">1.0</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>-3.1406524890731258
</code></pre>
<p>Querying with <code>Chains</code> object is easy as well:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chn</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">Prior</span><span class="x">(),</span> <span class="mi">10</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (10×3×1 Array{Float64, 3}):

Iterations        = 1:1:10
Number of chains  = 1
Samples per chain = 10
Wall duration     = 0.39 seconds
Compute duration  = 0.39 seconds
parameters        = s, m
internals         = lp

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

           s    2.3521    1.0661    0.4174     4.9687    10.0000    1.4156 
    ⋯
           m   -0.2634    1.9127    0.6048    10.0000    10.0000    0.9681 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           s    1.1649    1.6899    2.0003    3.2842    4.0077
           m   -2.1049   -1.9263   -0.6289    0.9718    3.0625
</code></pre>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loglikelihood</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">chn</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>10×1 Matrix{Float64}:
 -1.152512581810826
 -3.209564317808394
 -1.2822047083624553
 -1.1774957331222868
 -2.784582448464323
 -3.5390362387698215
 -3.015852527660817
 -3.8036178159082445
 -1.744721992326117
 -2.431462231454251
</code></pre>
<h3 id="maximum-likelihood-and-maximum-a-posterior-estimates">Maximum likelihood and maximum a posterior estimates</h3>
<p>Turing provides support for two mode estimation techniques, <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a> (MLE) and <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">maximum a posterior</a> (MAP) estimation. Optimization is performed by the <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> package. Mode estimation is currently a optional tool, and will not be available to you unless you have manually installed Optim and loaded the package with a <code>using</code> statement. To install Optim, run <code>import Pkg; Pkg.add(&quot;Optim&quot;)</code>.</p>
<p>Mode estimation only works when all model parameters are continuous -- discrete parameters cannot be estimated with MLE/MAP as of yet.</p>
<p>To understand how mode estimation works, let us first load Turing and Optim to enable mode estimation, and then declare a model:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Note that loading Optim explicitly is required for mode estimation to function,</span>
<span class="c"># as Turing does not load the opimization suite unless Optim is loaded as well.</span>
<span class="k">using</span> <span class="n">Turing</span>
<span class="k">using</span> <span class="n">Optim</span>

<span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="n">s²</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s²</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>gdemo (generic function with 6 methods)
</code></pre>
<p>Once the model is defined, we can construct a model instance as we normally would:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create some data to pass to the model.</span>
<span class="n">data</span> <span class="o">=</span> <span class="x">[</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">]</span>

<span class="c"># Instantiate the gdemo model with our data.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">data</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>DynamicPPL.Model{typeof(Main.var&quot;##WeaveSandBox#413&quot;.gdemo), (:x,), (), (),
 Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}(Main.var&quot;##Wea
veSandBox#413&quot;.gdemo, (x = [1.5, 2.0],), NamedTuple(), DynamicPPL.DefaultCo
ntext())
</code></pre>
<p>Mode estimation is typically quick and easy at this point. Turing extends the function <code>Optim.optimize</code> and accepts the structs <code>MLE()</code> or <code>MAP()</code>, which inform Turing whether to provide an MLE or MAP estimate, respectively. By default, the <a href="https://julianlsolvers.github.io/Optim.jl/stable/#algo/lbfgs/">LBFGS optimizer</a> is used, though this can be changed. Basic usage is:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Generate a MLE estimate.</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">())</span>

<span class="c"># Generate a MAP estimate.</span>
<span class="n">map_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MAP</span><span class="x">())</span>
</code></pre></div></div>
<pre><code>ModeResult with maximized lp of -4.62
[0.9074074074073607, 1.1666666666663343]
</code></pre>
<p>If you wish to change to a different optimizer, such as <code>NelderMead</code>, simply place your optimizer in the third argument slot:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use NelderMead</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">NelderMead</span><span class="x">())</span>

<span class="c"># Use SimulatedAnnealing</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">SimulatedAnnealing</span><span class="x">())</span>

<span class="c"># Use ParticleSwarm</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">ParticleSwarm</span><span class="x">())</span>

<span class="c"># Use Newton</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">Newton</span><span class="x">())</span>

<span class="c"># Use AcceleratedGradientDescent</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">AcceleratedGradientDescent</span><span class="x">())</span>
</code></pre></div></div>
<p>Some methods may have trouble calculating the mode because not enough iterations were allowed, or the target function moved upwards between function calls. Turing will warn you if Optim fails to converge by running <code>Optim.converge</code>. A typical solution to this might be to add more iterations, or allow the optimizer to increase between function iterations:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Increase the iterations and allow function eval to increase between calls.</span>
<span class="n">mle_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span>
    <span class="n">model</span><span class="x">,</span> <span class="n">MLE</span><span class="x">(),</span> <span class="n">Newton</span><span class="x">(),</span> <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="x">(;</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">10_000</span><span class="x">,</span> <span class="n">allow_f_increases</span><span class="o">=</span><span class="nb">true</span><span class="x">)</span>
<span class="x">)</span>
</code></pre></div></div>
<p>More options for Optim are available <a href="https://julianlsolvers.github.io/Optim.jl/stable/#user/config/">here</a>.</p>
<h4 id="analyzing-your-mode-estimate">Analyzing your mode estimate</h4>
<p>Turing extends several methods from <code>StatsBase</code> that can be used to analyze your mode estimation results. Methods implemented include <code>vcov</code>, <code>informationmatrix</code>, <code>coeftable</code>, <code>params</code>, and <code>coef</code>, among others.</p>
<p>For example, let's examine our ML estimate from above using <code>coeftable</code>:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import StatsBase to use it's statistical methods.</span>
<span class="k">using</span> <span class="n">StatsBase</span>

<span class="c"># Print out the coefficient table.</span>
<span class="n">coeftable</span><span class="x">(</span><span class="n">mle_estimate</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>─────────────────────────────
   estimate  stderror   tstat
─────────────────────────────
s    0.0625  0.0625    1.0
m    1.75    0.176777  9.8995
─────────────────────────────
</code></pre>
<p>Standard errors are calculated from the Fisher information matrix (inverse Hessian of the log likelihood or log joint). t-statistics will be familiar to frequentist statisticians. Warning -- standard errors calculated in this way may not always be appropriate for MAP estimates, so please be cautious in interpreting them.</p>
<h4 id="sampling-with-the-mapmle-as-initial-states">Sampling with the MAP/MLE as initial states</h4>
<p>You can begin sampling your chain from an MLE/MAP estimate by extracting the vector of parameter values and providing it to the <code>sample</code> function with the keyword <code>initial_params</code>. For example, here is how to sample from the full posterior using the MAP estimate as the starting point:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Generate an MAP estimate.</span>
<span class="n">map_estimate</span> <span class="o">=</span> <span class="n">optimize</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">MAP</span><span class="x">())</span>

<span class="c"># Sample with the MAP estimate as the starting point.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">NUTS</span><span class="x">(),</span> <span class="mi">1_000</span><span class="x">;</span> <span class="n">initial_params</span><span class="o">=</span><span class="n">map_estimate</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">array</span><span class="x">)</span>
</code></pre></div></div>
<h2 id="beyond-the-basics">Beyond the Basics</h2>
<h3 id="compositional-sampling-using-gibbs">Compositional Sampling Using Gibbs</h3>
<p>Turing.jl provides a Gibbs interface to combine different samplers. For example, one can combine an <code>HMC</code> sampler with a <code>PG</code> sampler to run inference for different parameters in a single model as below.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> simple_choice</span><span class="x">(</span><span class="n">xs</span><span class="x">)</span>
    <span class="n">p</span> <span class="o">~</span> <span class="n">Beta</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">z</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="x">(</span><span class="n">p</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">xs</span><span class="x">)</span>
        <span class="k">if</span> <span class="n">z</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">xs</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
        <span class="k">else</span>
            <span class="n">xs</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
        <span class="k">end</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="n">simple_choice_f</span> <span class="o">=</span> <span class="n">simple_choice</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">,</span> <span class="mf">0.3</span><span class="x">])</span>

<span class="n">chn</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">simple_choice_f</span><span class="x">,</span> <span class="n">Gibbs</span><span class="x">(</span><span class="n">HMC</span><span class="x">(</span><span class="mf">0.2</span><span class="x">,</span> <span class="mi">3</span><span class="x">,</span> <span class="o">:</span><span class="n">p</span><span class="x">),</span> <span class="n">PG</span><span class="x">(</span><span class="mi">20</span><span class="x">,</span> <span class="o">:</span><span class="n">z</span><span class="x">)),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>
<pre><code>Chains MCMC chain (1000×3×1 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 15.52 seconds
Compute duration  = 15.52 seconds
parameters        = p, z
internals         = lp

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

           p    0.4408    0.2047    0.0206    98.8899   136.7330    1.0129 
    ⋯
           z    0.1920    0.3941    0.0221   317.1798        NaN    0.9999 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           p    0.1122    0.2779    0.4240    0.6007    0.8589
           z    0.0000    0.0000    0.0000    0.0000    1.0000
</code></pre>
<p>The <code>Gibbs</code> sampler can be used to specify unique automatic differentiation backends for different variable spaces. Please see the <a href="%7B%7Bsite.baseurl%7D%7D/docs/using-turing/autodiff">Automatic Differentiation</a> article for more.</p>
<p>For more details of compositional sampling in Turing.jl, please check the corresponding <a href="http://proceedings.mlr.press/v84/ge18b.html">paper</a>.</p>
<h3 id="working-with-filldist-and-arraydist">Working with filldist and arraydist</h3>
<p>Turing provides <code>filldist(dist::Distribution, n::Int)</code> and <code>arraydist(dists::AbstractVector{&lt;:Distribution})</code> as a simplified interface to construct product distributions, e.g., to model a set of variables that share the same structure but vary by group.</p>
<h4 id="constructing-product-distributions-with-filldist">Constructing product distributions with filldist</h4>
<p>The function <code>filldist</code> provides a general interface to construct product distributions over distributions of the same type and parameterisation.
Note that, in contrast to the product distribution interface provided by Distributions.jl (<code>Product</code>), <code>filldist</code> supports product distributions over univariate or multivariate distributions.</p>
<p>Example usage:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> demo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">g</span><span class="x">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">length</span><span class="x">(</span><span class="n">unique</span><span class="x">(</span><span class="n">g</span><span class="x">))</span>
    <span class="n">a</span> <span class="o">~</span> <span class="n">filldist</span><span class="x">(</span><span class="n">Exponential</span><span class="x">(),</span> <span class="n">k</span><span class="x">)</span> <span class="c"># = Product(fill(Exponential(), k))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">a</span><span class="x">[</span><span class="n">g</span><span class="x">]</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">.~</span> <span class="n">Normal</span><span class="o">.</span><span class="x">(</span><span class="n">mu</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>demo (generic function with 2 methods)
</code></pre>
<h4 id="constructing-product-distributions-with-arraydist">Constructing product distributions with arraydist</h4>
<p>The function <code>arraydist</code> provides a general interface to construct product distributions over distributions of varying type and parameterisation.
Note that in contrast to the product distribution interface provided by Distributions.jl (<code>Product</code>), <code>arraydist</code> supports product distributions over univariate or multivariate distributions.</p>
<p>Example usage:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> demo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">g</span><span class="x">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">length</span><span class="x">(</span><span class="n">unique</span><span class="x">(</span><span class="n">g</span><span class="x">))</span>
    <span class="n">a</span> <span class="o">~</span> <span class="n">arraydist</span><span class="x">([</span><span class="n">Exponential</span><span class="x">(</span><span class="n">i</span><span class="x">)</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">k</span><span class="x">])</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">a</span><span class="x">[</span><span class="n">g</span><span class="x">]</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">.~</span> <span class="n">Normal</span><span class="o">.</span><span class="x">(</span><span class="n">mu</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>
<pre><code>demo (generic function with 2 methods)
</code></pre>
<h3 id="working-with-mcmcchainsjl">Working with MCMCChains.jl</h3>
<p>Turing.jl wraps its samples using <code>MCMCChains.Chain</code> so that all the functions working for <code>MCMCChains.Chain</code> can be re-used in Turing.jl. Two typical functions are <code>MCMCChains.describe</code> and <code>MCMCChains.plot</code>, which can be used as follows for an obtained chain <code>chn</code>. For more information on <code>MCMCChains</code>, please see the <a href="https://github.com/TuringLang/MCMCChains.jl">GitHub repository</a>.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">describe</span><span class="x">(</span><span class="n">chn</span><span class="x">)</span> <span class="c"># Lists statistics of the samples.</span>
<span class="n">plot</span><span class="x">(</span><span class="n">chn</span><span class="x">)</span> <span class="c"># Plots statistics of the samples.</span>
</code></pre></div></div>
<p><img src="/dev/tutorials/figures/using-turing-guide_39_1.png" alt="" /></p>
<p>There are numerous functions in addition to <code>describe</code> and <code>plot</code> in the <code>MCMCChains</code> package, such as those used in convergence diagnostics. For more information on the package, please see the <a href="https://github.com/TuringLang/MCMCChains.jl">GitHub repository</a>.</p>
<h3 id="changing-default-settings">Changing Default Settings</h3>
<p>Some of Turing.jl's default settings can be changed for better usage.</p>
<h4 id="ad-chunk-size">AD Chunk Size</h4>
<p>ForwardDiff (Turing's default AD backend) uses forward-mode chunk-wise AD. The chunk size can be set manually by <code>setchunksize(new_chunk_size)</code>.</p>
<h4 id="ad-backend">AD Backend</h4>
<p>Turing supports four packages of automatic differentiation (AD) in the back end during sampling. The default AD backend is <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff</a> for forward-mode AD. Three reverse-mode AD backends are also supported, namely <a href="https://github.com/FluxML/Tracker.jl">Tracker</a>, <a href="https://github.com/FluxML/Zygote.jl">Zygote</a> and <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff</a>. <code>Zygote</code> and <code>ReverseDiff</code> are supported optionally if explicitly loaded by the user with <code>using Zygote</code> or <code>using ReverseDiff</code> next to <code>using Turing</code>.</p>
<p>For more information on Turing's automatic differentiation backend, please see the <a href="%7B%7Bsite.baseurl%7D%7D/docs/using-turing/autodiff">Automatic Differentiation</a> article.</p>
<h4 id="progress-logging">Progress Logging</h4>
<p><code>Turing.jl</code> uses ProgressLogging.jl to log the progress of sampling. Progress
logging is enabled as default but might slow down inference. It can be turned on
or off by setting the keyword argument <code>progress</code> of <code>sample</code> to <code>true</code> or <code>false</code>, respectively. Moreover, you can enable or disable progress logging globally by calling <code>setprogress!(true)</code> or <code>setprogress!(false)</code>, respectively.</p>
<p>Turing uses heuristics to select an appropriate visualization backend. If you
use <a href="https://junolab.org/">Juno</a>, the progress is displayed with a
<a href="http://docs.junolab.org/latest/man/juno_frontend/#Progress-Meters-1">progress bar in the Atom window</a>.
For Jupyter notebooks the default backend is
<a href="https://github.com/tkf/ConsoleProgressMonitor.jl">ConsoleProgressMonitor.jl</a>.
In all other cases, progress logs are displayed with
<a href="https://github.com/c42f/TerminalLoggers.jl">TerminalLoggers.jl</a>. Alternatively,
if you provide a custom visualization backend, Turing uses it instead of the
default backend.</p>

    
<script
src="https://code.jquery.com/jquery-3.3.1.min.js"
integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
crossorigin="anonymous"></script>

<script>
$(document).ready(function() {

    var toc = $('#nav-toc');

    // Select each header
    sections = $('#md-container-pancakes h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¶')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link toc-side-bar" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil( "h1" );
            $.each(contenders, function(idx, contender){
            if($(contender).is('h2')) {
                var contender_id = $(contender).attr('id');
                var contender_text = $(contender).text().split('¶')[0];
                var content = '<li class="md-nav__item"><a class="md-nav__link toc-side-bar" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                children.append(content);
                }
            })
            $("#link_" + div_id).append(children);
        });
    });
</script>
    <!-- this will parse through the header fields and add a button to open
     an issue / ask a question on Github. The editable field should be in
     the post frontend matter, and refer to the label to open the issue for -->

<style>
.more {
    float:right;
    font-size: 1.0rem !important;
}
.more:hover {
    color: cornflowerblue !important;
}

.dropdown {
    position: relative;
    display: inline-block;
}

.dropdown-content {
    display: none;
    position: absolute;
    background-color: #f9f9f9;
    min-width: 160px;
    font-weight: 200;
    box-shadow: 0px 8px 6px 0px rgba(0,0,0,0.2);
    padding: 0px 10px;
    z-index: 1;
}

.dropdown:hover .dropdown-content {
    display: block;
}
</style>


    </article>
</div>      

                </div>
            </div>
        </main>
    </div>

    <footer class="c-footer md-footer-nav">
  <div class="md-footer-copyright__highlight">
    
    Turing is created by <a style="color:inherit; text-decoration: underline;" href="http://mlg.eng.cam.ac.uk/hong/">Hong Ge</a>, 
    and lovingly maintained by the <a style="color:inherit; text-decoration: underline;" href="https://github.com/TuringLang/Turing.jl/graphs/contributors">core team</a> of volunteers.

    <br><br>
    
    The contents of this website are
© 2024 under the terms of the <a style="color:inherit; text-decoration: underline;" href="https://github.com/TuringLang/Turing.jl/blob/master/LICENCE">MIT License</a>.
    
  </div>  
</footer>


    <script src="/dev/assets/js/application.js"></script>
    
    <script>console.log('4')</script>
    <script>app.initialize({version:"0.17.4", url:{base:'/dev'}})</script>

    
    <script src="/dev/assets/js/version-switch.js"></script>

    <script>
 var headers = ["h1", "h2", "h3", "h4"]
 var colors = ["red", "orange", "green", "blue"]

 $.each(headers, function(i, header){
   var color = colors[i];
   $(header).each(function () {
     var href=$(this).attr("id");
     $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¶</a>')
   });
 })

 // Ensure that sidebar on left has arrows
 $(".pancakes-parent").on('click', function(){
   console.log($(this).next());
   $(this).next().find('.pancakes-child').toggle();
   if ($(this).hasClass('open-parent')){
     $(this).removeClass('open-parent');
   } else {
     $(this).addClass('open-parent');
   }
 })

 $(".pancakes-parent-mobile").on('click', function(){
   var nav = $(this).next();
   nav.addClass('mobile-sub-navbar-display');
 })

 $(".mobile-navbar-back").on('click', function(){
   var nav = $(this).parent();
   nav.removeClass('mobile-sub-navbar-display');
 })

</script>

<script>
 MathJax = {
   tex: {
     inlineMath: [['$', '$'], ['$$', '$$']]
   }
 };
</script>
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

    <script>
$('h1').first().append('<div></div>')</script>

    <style>
#scrolltop {
  display: none; /* Hidden by default */
  position: fixed; /* Fixed/sticky position */
  bottom: 20px; /* Place the button at the bottom of the page */
  right: 30px; /* Place the button 30px from the right */
  z-index: 99; /* Make sure it does not overlap */
  border: none; /* Remove borders */
  outline: none; /* Remove outline */
  background-color: #d2e6f5; /* Set a background color */
  color: white; /* Text color */
  cursor: pointer; /* Add a mouse pointer on hover */
  padding: 10px 15px; /* Some padding */
  border-radius: 100px; /* Rounded corners */
  font-size: 18px; /* Increase font size */
  font-weight: 600;
}

#scrolltop:hover {
  background-color: #555; /* Add a dark-grey background on hover */
}
</style>
<button onclick="topFunction()" id="scrolltop" title="Go to top">🔝</button>

<script>
// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    document.getElementById("scrolltop").style.display = "block";
  } else {
    document.getElementById("scrolltop").style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0; // For Safari
  document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
}
</script>

    


  </body>
</html>
