<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Turing.jl</title>
<link>https://turinglang.org/news/</link>
<atom:link href="https://turinglang.org/news/index.xml" rel="self" type="application/rss+xml"/>
<description>Turing.jl is a probabilistic programming language and Bayesian modelling framework for the Julia programming language.</description>
<image>
<url>https://turinglang.org/assets/logo/turing-text-logo.jpg</url>
<title>Turing.jl</title>
<link>https://turinglang.org/news/</link>
</image>
<generator>quarto-1.7.34</generator>
<lastBuildDate>Mon, 01 Sep 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>GSoC Report for DoodleBUGS: a Browser-Based Graphical Interface for Drawing Probabilistic Graphical Models</title>
  <dc:creator>Shravan Goswami</dc:creator>
  <link>https://turinglang.org/news/posts/2025-09-01-GSoC-Report-DoodleBUGS/</link>
  <description><![CDATA[ 





<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<ul>
<li>BUGS (Bayesian Inference Using Gibbs Sampling) is a probabilistic programming language for Bayesian models, and JuliaBUGS is its modern implementation in Julia. DoodleBUGS is a browser-based graphical interface for JuliaBUGS, allowing users to draw probabilistic graphical models and generate BUGS code.</li>
<li>Implemented: visual editor (nodes, edges, nested plates), legacy BUGS code generation that compiles with <a href="https://github.com/TuringLang/JuliaBUGS.jl">JuliaBUGS</a> <span class="citation" data-cites="JuliaBUGS bugs-book">[1], [2]</span>, local execution via a Julia backend, unified standalone script generation (frontend), timeouts, multiple layouts, and extensive cleanup/typing.</li>
<li>Changed from proposal: frontend implemented in Vue 3 (instead of React); backend simplified (frontend is the single source of truth for standalone scripts).</li>
<li>Status: Working application. Try it here (static UI): <a href="https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/">https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/</a>. For local inference, run the backend server.</li>
</ul>
</section>
<section id="doodlebugs-ui" class="level2">
<h2 class="anchored" data-anchor-id="doodlebugs-ui">DoodleBUGS UI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://turinglang.org/news/posts/2025-09-01-GSoC-Report-DoodleBUGS/DoodleBUGS.png" class="img-fluid figure-img"></p>
<figcaption>DoodleBUGS UI</figcaption>
</figure>
</div>
</section>
<section id="doodlebugs-project-structure" class="level2">
<h2 class="anchored" data-anchor-id="doodlebugs-project-structure">DoodleBUGS Project Structure</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">DoodleBUGS/</span>                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Vite + Vue 3 app (UI editor)</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> README.md              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># project documentation</span></span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> public/                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># static assets served by Vite</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   └── examples/          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># example projects</span></span>
<span id="cb1-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> experiments/           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># prototypes and exploratory work</span></span>
<span id="cb1-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> runtime/               <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Julia HTTP backend (API endpoints &amp; dependencies)</span></span>
<span id="cb1-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> src/                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># application source</span></span>
<span id="cb1-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├── assets/            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># styles and static assets</span></span>
<span id="cb1-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├── components/        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Vue components composing the UI</span></span>
<span id="cb1-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── canvas/        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># graph canvas and toolbars</span></span>
<span id="cb1-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── common/        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shared UI primitives</span></span>
<span id="cb1-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── layouts/       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># app layout and modals</span></span>
<span id="cb1-13"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   │   └── MainLayout.vue   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># main application layout</span></span>
<span id="cb1-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── left-sidebar/  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># palette, project manager, execution settings</span></span>
<span id="cb1-15"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── panels/        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># code preview and data input panels</span></span>
<span id="cb1-16"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── right-sidebar/ <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># execution, JSON editor, node properties</span></span>
<span id="cb1-17"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   └── ui/            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># base UI elements (buttons, inputs, selects)</span></span>
<span id="cb1-18"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├── composables/       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reusable logic (codegen, drag &amp; drop, graph, validator, grid)</span></span>
<span id="cb1-19"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├── config/            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># configuration and node definitions</span></span>
<span id="cb1-20"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├── stores/            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pinia state stores (graph, data, execution, project, UI)</span></span>
<span id="cb1-21"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   └── types/             <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># TypeScript types and ambient declarations</span></span>
<span id="cb1-22"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> tmp/                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># local temporary outputs (ignored in builds)</span></span>
<span id="cb1-23"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">└──</span> ztest/                 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># scratch/test artifacts</span></span></code></pre></div>
</section>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p><a href="https://github.com/TuringLang/JuliaBUGS.jl">JuliaBUGS</a> is a modern Julia implementation of the BUGS language <span class="citation" data-cites="bugs-rjournal bugs-book bugs-project">[2], [3], [4]</span>. DoodleBUGS revives the original visual modelling concept with a modern browser-based stack so users can:</p>
<ul>
<li>Construct probabilistic graphical models visually (nodes, edges, plates).</li>
<li>Export readable legacy BUGS code that compiles with JuliaBUGS <span class="citation" data-cites="JuliaBUGS bugs-rjournal bugs-book">[1], [2], [3]</span>.</li>
<li>Run inference and inspect results from the UI. Common BUGS applications include parallel MCMC <span class="citation" data-cites="multibugs">[5]</span>, survival analysis <span class="citation" data-cites="bugs-survival">[6]</span>, and Gibbs-style samplers <span class="citation" data-cites="albert-chib-1993 informs-gibbs">[7], [8]</span>.</li>
</ul>
</section>
<section id="what-was-built" class="level2">
<h2 class="anchored" data-anchor-id="what-was-built">What Was Built</h2>
<ul>
<li>Visual editor
<ul>
<li>Node types: stochastic, observed, deterministic</li>
<li>Plates with arbitrary nesting; robust drag-in/out and creation inside plates</li>
<li>Graph layouts: Dagre (default), fCoSE (Force-Directed), Cola (Physics Simulation), KLay (Layered); stable interactions</li>
</ul></li>
<li>Legacy BUGS code generation <span class="citation" data-cites="bugs-rjournal bugs-book">[2], [3]</span>
<ul>
<li>Topological ordering and plate-aware traversal</li>
<li>Parameter formatting and safe index expansion</li>
<li>Implemented in <code>DoodleBUGS/src/composables/useBugsCodeGenerator.ts</code></li>
</ul></li>
<li>Execution flow
<ul>
<li>Frontend POSTs to <code>/api/run</code> with body: <code>model_code</code> (BUGS), <code>data</code> and <code>inits</code> (JSON), <code>data_string</code> and <code>inits_string</code> (Julia NamedTuple literals), and <code>settings</code> <code>{ n_samples, n_adapts, n_chains, seed, timeout_s }</code>. If <code>/api/run</code> returns 404, it falls back to <code>/api/run_model</code>.</li>
<li>Backend creates a temp dir, writes <code>model.bugs</code> and <code>payload.json</code>, generates an ephemeral <code>run_script.jl</code>, compiles with <code>JuliaBUGS.@bugs</code>, wraps with <code>ADgradient(:ReverseDiff)</code>, and samples via <code>AdvancedHMC.NUTS</code> through <code>AbstractMCMC</code> (Threads or Serial). It writes summaries (incl.&nbsp;ESS, R-hat) and quantiles to JSON and returns <code>{ success, summary, quantiles, logs, files[] }</code>, where <code>files</code> includes <code>model.bugs</code>, <code>payload.json</code>, <code>run_script.jl</code>, and <code>results.json</code>.</li>
<li>Frontend also generates a <code>standalone.jl</code> script locally (mirrors backend execution) and shows it alongside the backend files; the backend does not attach a standalone script.</li>
</ul></li>
<li>Timeouts/resilience
<ul>
<li>Configurable timeout (frontend); enforced in backend worker</li>
<li>Safe temp directory cleanup on Windows with retries</li>
</ul></li>
<li>Cleanup/typing
<ul>
<li>Strong, project-wide TypeScript typing across stores, components, and composables</li>
<li>Removal of unused backend code; consistent naming and logs</li>
</ul></li>
</ul>
</section>
<section id="architecture-overview" class="level2">
<h2 class="anchored" data-anchor-id="architecture-overview">Architecture Overview</h2>
<ul>
<li>Frontend: <a href="https://vuejs.org/">Vue 3</a>, <a href="https://pinia.vuejs.org/">Pinia</a>, <a href="https://js.cytoscape.org/">Cytoscape.js</a> <span class="citation" data-cites="cytoscapejs">[9]</span>, <a href="https://codemirror.net/">CodeMirror</a>
<ul>
<li>Code generation: <code>DoodleBUGS/src/composables/useBugsCodeGenerator.ts</code></li>
<li>Execution panel: <code>DoodleBUGS/src/components/right-sidebar/ExecutionPanel.vue</code></li>
</ul></li>
<li>Backend (Julia) HTTP server
<ul>
<li>Server: <code>DoodleBUGS/runtime/server.jl</code></li>
<li>Project deps: <code>DoodleBUGS/runtime/Project.toml</code> (HTTP, JSON3, JuliaBUGS, AbstractMCMC, AdvancedHMC, ReverseDiff, MCMCChains, DataFrames, StatsBase, Statistics)</li>
<li>Endpoints: GET <code>/api/health</code>; POST <code>/api/run</code> and <code>/api/run_model</code></li>
<li>Execution: creates temp dir, writes <code>model.bugs</code> and <code>payload.json</code>, generates <code>run_script.jl</code>, enforces optional timeout</li>
</ul></li>
</ul>
</section>
<section id="design-principles-and-architecture" class="level2">
<h2 class="anchored" data-anchor-id="design-principles-and-architecture">Design Principles and Architecture</h2>
<p><strong>Design principles</strong></p>
<ul>
<li>Visual-first modeling with deterministic export to legacy BUGS <span class="citation" data-cites="bugs-rjournal bugs-book">[2], [3]</span>.</li>
<li>Separation of concerns: editing (graph), generation (BUGS), execution (backend), and results (summary/quantiles) are modular.</li>
<li>Deterministic ordering: topological sort + plate-aware traversal ensures readable, stable code output.</li>
<li>Robustness: cancellable frontend fetch, backend-enforced timeout, and resilient temp cleanup on Windows (<code>safe_rmdir()</code>).</li>
</ul>
<p><strong>Frontend architecture (Vue 3 + Cytoscape.js)</strong></p>
<ul>
<li>Core graph state is managed in Vue; <a href="https://js.cytoscape.org/">Cytoscape.js</a> handles layout, hit-testing, and interaction semantics (including compound nodes for plates) <span class="citation" data-cites="cytoscapejs">[9]</span>.</li>
<li>Code generation lives in <code>DoodleBUGS/src/composables/useBugsCodeGenerator.ts</code> and maps <code>GraphNode</code>/<code>GraphEdge</code> to BUGS:
<ul>
<li>Kahn topological sort for definition order</li>
<li>Plate-aware recursion for <code>for (...) { ... }</code> blocks</li>
<li>Parameter canonicalization (indices, numeric/expr passthrough)</li>
</ul></li>
<li>Standalone Julia script generation uses <code>generateStandaloneScript()</code> in the same composable, mirroring backend execution.</li>
</ul>
<p><strong>Backend architecture (Julia)</strong></p>
<ul>
<li><code>run_model_handler()</code> in <code>DoodleBUGS/runtime/server.jl</code> materializes <code>model.bugs</code>, <code>payload.json</code>, and a transient <code>run_script.jl</code> that:
<ul>
<li>Builds <code>NamedTuple</code>s from JSON or string-literal data/inits</li>
<li>Compiles via <code>JuliaBUGS.@bugs</code>, wraps with <code>ADgradient(:ReverseDiff)</code> <span class="citation" data-cites="ReverseDiff">[10]</span></li>
<li>Samples with <code>AdvancedHMC.NUTS</code> through <code>AbstractMCMC</code> (Threads or Serial) <span class="citation" data-cites="AdvancedHMC AbstractMCMC HoffmanGelman2014">[11], [12], [13]</span></li>
<li>Emits summaries (incl.&nbsp;ESS and R-hat) via <code>MCMCChains</code>/<code>DataFrames</code> and quantiles to JSON <span class="citation" data-cites="MCMCChains DataFrames">[14], [15]</span></li>
<li>Timeout: worker process is killed if exceeding <code>timeout_s</code>.</li>
<li>Cleanup: <code>safe_rmdir()</code> retries with GC to avoid EBUSY on Windows.</li>
</ul></li>
</ul>
</section>
<section id="why-vue-not-react" class="level2">
<h2 class="anchored" data-anchor-id="why-vue-not-react">Why Vue (not React)?</h2>
<p>The proposal planned React; we chose Vue 3 after evaluating the graph layer and developer velocity for this app.</p>
<ul>
<li>Tried Konva (canvas) for custom graph editing: powerful drawing primitives, but required bespoke graph semantics (hit testing, edge routing, compound nodes) that <a href="https://js.cytoscape.org/">Cytoscape.js</a> provides out of the box.</li>
<li>Tried D3 force/layouts: flexible, but compound nodes (plates), nesting, and drag constraints became a significant amount of custom code to maintain.</li>
<li><a href="https://js.cytoscape.org/">Cytoscape.js</a> offered:
<ul>
<li>Native graph model with compound nodes (great for plates)</li>
<li>Integrated layouts (Dagre, fCoSE, Cola, KLay) and rich interaction APIs <span class="citation" data-cites="webcola elk">[16], [17]</span></li>
<li>Mature ecosystem and performance characteristics for medium-sized graphs</li>
</ul></li>
<li><a href="https://vuejs.org/">Vue 3</a> (vs React) for this project:
<ul>
<li>Composition API made integrating an imperative graph library (Cytoscape) straightforward via composables and lifecycle hooks</li>
<li>SFC ergonomics and Pinia stores enabled quick iteration with strong TypeScript support</li>
<li>Template reactivity + refs reduced reconciliation overhead when bridging to Cytoscape’s imperative API</li>
<li>Minimal glue code for state management (Pinia) vs setting up reducers/selectors; enabled rapid iteration</li>
<li>Vite + Vue tooling yielded fast HMR for UI-heavy iterations</li>
</ul></li>
<li>Design inspirations: draw.io for interaction affordances; Stan Playground for model/run UX <span class="citation" data-cites="drawio stan-playground">[18], [19]</span>.</li>
</ul>
</section>
<section id="comparison-to-legacy-doodlebugs" class="level2">
<h2 class="anchored" data-anchor-id="comparison-to-legacy-doodlebugs">Comparison to Legacy DoodleBUGS</h2>
<p>The legacy tool was a windows desktop application driving WinBUGS <span class="citation" data-cites="winbugs">[20]</span>; the new DoodleBUGS is a browser-based editor targeting JuliaBUGS <span class="citation" data-cites="JuliaBUGS">[1]</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://turinglang.org/news/posts/2025-09-01-GSoC-Report-DoodleBUGS/Legacy-DoodleBUGS.png" class="img-fluid figure-img"></p>
<figcaption>Legacy DoodleBUGS</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://turinglang.org/news/posts/2025-09-01-GSoC-Report-DoodleBUGS/New-DoodleBUGS.png" class="img-fluid figure-img"></p>
<figcaption>New DoodleBUGS</figcaption>
</figure>
</div>
<p>Key differences:</p>
<ul>
<li>Platform and backend
<ul>
<li>Legacy: Desktop UI, WinBUGS execution pipeline</li>
<li>New: Web UI, Julia backend via <code>JuliaBUGS.@bugs</code>, sampling with <code>AdvancedHMC.NUTS</code> through <code>AbstractMCMC</code></li>
</ul></li>
<li>Graph engine and plates
<ul>
<li>Legacy: Bespoke graph handling with limited nesting semantics</li>
<li>New: <a href="https://js.cytoscape.org/">Cytoscape.js</a> with compound nodes for robust nested plates; custom drag-and-drop for drag-in/out and creating inside plates</li>
</ul></li>
<li>Layouts and interactions
<ul>
<li>Legacy: Limited auto-layout support</li>
<li>New: Multiple layout engines (Dagre, fCoSE, Cola, KLay) and stable interactions; positions updated after <code>layoutstop</code> <span class="citation" data-cites="webcola elk">[16], [17]</span></li>
</ul></li>
<li>Code generation
<ul>
<li>Legacy: Export to BUGS without strong ordering guarantees</li>
<li>New: Deterministic topological + plate-aware traversal; parameter canonicalization and safe index expansion</li>
</ul></li>
<li>Execution and tooling
<ul>
<li>Legacy: WinBUGS-managed runs</li>
<li>New: Lightweight Julia HTTP backend, configurable timeouts, resilient temp cleanup, JSON summaries via <code>MCMCChains</code></li>
</ul></li>
<li>DevX and maintainability
<ul>
<li>New: Vue 3 + TypeScript + Pinia; unified standalone script generation on the frontend; leaner backend responses</li>
</ul></li>
</ul>
</section>
<section id="progress-vs-proposal" class="level2">
<h2 class="anchored" data-anchor-id="progress-vs-proposal">Progress vs Proposal</h2>
<ul>
<li>Implemented
<ul>
<li>Visual editor with nested plates and robust drag-and-drop</li>
<li>BUGS code generator (topological + plate-aware)</li>
<li>Local execution + summaries/quantiles</li>
<li>Unified standalone script generation (frontend)</li>
<li>Timeouts/resilience</li>
<li>Multiple layouts and interactions</li>
<li>Extensive cleanup/typing</li>
<li>Execution timeout (end-to-end)</li>
<li>Layout options (Dagre (default, layered), fCoSE (force-directed), Cola (physics simulation), KLay (layered)) and interactions</li>
<li>Cleanup and stronger typing</li>
</ul></li>
<li>Changed
<ul>
<li>Vue 3 instead of React</li>
<li>Backend responses smaller; no standalone script attachment</li>
</ul></li>
<li>Deferred/Partial
<ul>
<li>Visualizations: integrate with MCMCChains.jl for plots (trace, density, PPC, diagnostics). ESS and R-hat already included in summary statistics.</li>
<li>WebKit/Safari support</li>
<li>UX polish for large graphs</li>
</ul></li>
</ul>
</section>
<section id="how-to-run-locally" class="level2">
<h2 class="anchored" data-anchor-id="how-to-run-locally">How to Run Locally</h2>
<p>Frontend (Vite):</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># from repo root</span></span>
<span id="cb2-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> DoodleBUGS</span>
<span id="cb2-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">npm</span> install</span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">npm</span> run dev</span></code></pre></div>
<p>Backend (Julia):</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># from repo root</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">julia</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--project</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>DoodleBUGS/runtime DoodleBUGS/runtime/server.jl</span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># server listens on http://localhost:8081</span></span></code></pre></div>
<p>Notes:</p>
<ul>
<li>CORS is enabled in the backend so the dev UI can call <code>http://localhost:8081</code>.</li>
<li>Try it here (static UI): <a href="https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/">https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/</a></li>
</ul>
</section>
<section id="api-summary-for-backend-server" class="level2">
<h2 class="anchored" data-anchor-id="api-summary-for-backend-server">API Summary for Backend Server</h2>
<ul>
<li>GET <code>/api/health</code> → <code>{ "status": "ok" }</code></li>
<li>POST <code>/api/run</code> (alias: <code>/api/run_model</code>)
<ul>
<li>Body: <code>model_code</code>, <code>data</code> (JSON), <code>inits</code> (JSON), <code>data_string</code> (Julia literal), <code>inits_string</code> (Julia literal), <code>settings</code> <code>{ n_samples, n_adapts, n_chains, seed, timeout_s }</code></li>
<li>Response: <code>{ success, summary, quantiles, logs, files[] }</code> where <code>files[]</code> contains <code>model.bugs</code>, <code>payload.json</code>, <code>run_script.jl</code>, <code>results.json</code></li>
<li>Note: Frontend falls back to <code>/api/run_model</code> if <code>/api/run</code> is unavailable (404)</li>
</ul></li>
</ul>
<p>See <code>DoodleBUGS/runtime/server.jl</code>.</p>
</section>
<section id="current-limitations" class="level2">
<h2 class="anchored" data-anchor-id="current-limitations">Current Limitations</h2>
<ul>
<li>WebKit/Safari/iOS: unsupported at this time (see <code>DoodleBUGS/README.md</code>).</li>
<li>Limited visualization beyond summary/quantiles.</li>
<li>Overlapped plates (nodes with multiple parent plates) are currently not supported; see <a href="https://github.com/TuringLang/JuliaBUGS.jl/issues/362">#362</a>.</li>
</ul>
</section>
<section id="future-work" class="level2">
<h2 class="anchored" data-anchor-id="future-work">Future Work</h2>
<ul>
<li>Backend: Add Pluto.jl as a backend for supporting compound documents and QuartoNotebookRunner.jl for running notebooks.</li>
<li>Diagnostics/visualization: integrate with MCMCChains.jl for plots (trace, density, PPC, diagnostics). ESS and R-hat already available in summary stats.</li>
<li>UX: richer node templates, validation, distribution hints</li>
<li>Sharing: shareable links/cloud sync (projects already persisted locally)</li>
<li>Browser compatibility: WebKit/Safari and iOS/iPadOS</li>
<li>Performance: virtualization for large graphs</li>
</ul>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>Much appreciation goes to my mentors Xianda Sun and Hong Ge. The work is impossible without your help and support.</p>
<ul>
<li>Mentors: Xianda Sun (<a href="https://github.com/sunxd3">@sunxd3</a>) and Hong Ge (<a href="https://github.com/yebai">@yebai</a>)</li>
<li>TuringLang/JuliaBUGS community and contributors</li>
</ul>
</section>
<section id="appendix-project-links" class="level2">
<h2 class="anchored" data-anchor-id="appendix-project-links">Appendix: Project Links</h2>
<ul>
<li>Repo: <a href="https://github.com/TuringLang/JuliaBUGS.jl">https://github.com/TuringLang/JuliaBUGS.jl</a></li>
<li>Try it here: <a href="https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/">https://turinglang.org/JuliaBUGS.jl/DoodleBUGS/</a></li>
</ul>
</section>
<section id="prs-during-gsoc" class="level2">
<h2 class="anchored" data-anchor-id="prs-during-gsoc">PRs during GSoC:</h2>
<ul>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/321">#321 - Add ISSUE template for DoodleBUGS</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/339">#339 - DoodleBUGS Project: Phase 1</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/340">#340 - DoodleBUGS: update all workflows to run on relevent project only</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/341">#341 - Exclude navigation bar from DoodleBUGS project</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/347">#347 - DoodleBUGS: Basic Code Generation, Advanced Exports, and State Persistence</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/357">#357 - DoodleBUGS: Allow Nested Plates, add new layouts and fix lot of linting issues</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/368">#368 - New Folder Structure</a></li>
<li><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/388">#388 - DoodleBUGS Project: Phase 2 (Backend)</a></li>
</ul>



</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0">
<div id="ref-JuliaBUGS" class="csl-entry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline"><span>“JuliaBUGS.jl.”</span> Available: <a href="https://github.com/TuringLang/JuliaBUGS.jl">https://github.com/TuringLang/JuliaBUGS.jl</a></div>
</div>
<div id="ref-bugs-book" class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline"><span>“The BUGS book: A practical introduction to bayesian analysis.”</span> Wiley. Available: <a href="https://onlinelibrary.wiley.com/doi/10.1111/anzs.12058">https://onlinelibrary.wiley.com/doi/10.1111/anzs.12058</a></div>
</div>
<div id="ref-bugs-rjournal" class="csl-entry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline"><span>“The BUGS language.”</span> Available: <a href="https://journal.r-project.org/articles/RN-2006-005/RN-2006-005.pdf">https://journal.r-project.org/articles/RN-2006-005/RN-2006-005.pdf</a></div>
</div>
<div id="ref-bugs-project" class="csl-entry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline"><span>“The BUGS project.”</span> Available: <a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">https://www.mrc-bsu.cam.ac.uk/software/bugs/</a></div>
</div>
<div id="ref-multibugs" class="csl-entry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline"><span>“MultiBUGS: Parallel BUGS modeling.”</span> Available: <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC7116196/">https://pmc.ncbi.nlm.nih.gov/articles/PMC7116196/</a></div>
</div>
<div id="ref-bugs-survival" class="csl-entry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline"><span>“Bayesian survival analysis with BUGS.”</span> Available: <a href="https://onlinelibrary.wiley.com/doi/10.1002/sim.8933">https://onlinelibrary.wiley.com/doi/10.1002/sim.8933</a></div>
</div>
<div id="ref-albert-chib-1993" class="csl-entry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline"><span>“Inference via gibbs (albert &amp; chib).”</span> Available: <a href="https://apps.olin.wustl.edu/faculty/chib/papers/albertchibjb93.pdf">https://apps.olin.wustl.edu/faculty/chib/papers/albertchibjb93.pdf</a></div>
</div>
<div id="ref-informs-gibbs" class="csl-entry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline"><span>“Bayesian inference using gibbs sampling.”</span> Available: <a href="https://pubsonline.informs.org/doi/10.1287/ited.2013.0120">https://pubsonline.informs.org/doi/10.1287/ited.2013.0120</a></div>
</div>
<div id="ref-cytoscapejs" class="csl-entry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline"><span>“Cytoscape.js.”</span> Available: <a href="https://js.cytoscape.org/">https://js.cytoscape.org/</a></div>
</div>
<div id="ref-ReverseDiff" class="csl-entry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline"><span>“ReverseDiff.jl.”</span> Available: <a href="https://github.com/JuliaDiff/ReverseDiff.jl">https://github.com/JuliaDiff/ReverseDiff.jl</a></div>
</div>
<div id="ref-AdvancedHMC" class="csl-entry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline"><span>“AdvancedHMC.jl.”</span> Available: <a href="https://github.com/TuringLang/AdvancedHMC.jl">https://github.com/TuringLang/AdvancedHMC.jl</a></div>
</div>
<div id="ref-AbstractMCMC" class="csl-entry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline"><span>“AbstractMCMC.jl.”</span> Available: <a href="https://github.com/TuringLang/AbstractMCMC.jl">https://github.com/TuringLang/AbstractMCMC.jl</a></div>
</div>
<div id="ref-HoffmanGelman2014" class="csl-entry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">M. D. Hoffman and A. Gelman, <span>“The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo,”</span> <em>arXiv preprint arXiv:1111.4246</em>, 2014, Available: <a href="https://arxiv.org/abs/1111.4246">https://arxiv.org/abs/1111.4246</a></div>
</div>
<div id="ref-MCMCChains" class="csl-entry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline"><span>“MCMCChains.jl.”</span> Available: <a href="https://github.com/TuringLang/MCMCChains.jl">https://github.com/TuringLang/MCMCChains.jl</a></div>
</div>
<div id="ref-DataFrames" class="csl-entry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline"><span>“DataFrames.jl.”</span> Available: <a href="https://dataframes.juliadata.org/">https://dataframes.juliadata.org/</a></div>
</div>
<div id="ref-webcola" class="csl-entry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline"><span>“WebCola.”</span> Available: <a href="https://ialab.it.monash.edu/webcola/">https://ialab.it.monash.edu/webcola/</a></div>
</div>
<div id="ref-elk" class="csl-entry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline"><span>“Eclipse layout kernel (ELK / KLay).”</span> Available: <a href="https://www.eclipse.org/elk/">https://www.eclipse.org/elk/</a></div>
</div>
<div id="ref-drawio" class="csl-entry">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline"><span>“Draw.io (diagrams.net).”</span> Available: <a href="https://www.diagrams.net/">https://www.diagrams.net/</a></div>
</div>
<div id="ref-stan-playground" class="csl-entry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline"><span>“Stan playground.”</span> Available: <a href="https://stan-playground.flatironinstitute.org/">https://stan-playground.flatironinstitute.org/</a></div>
</div>
<div id="ref-winbugs" class="csl-entry">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline"><span>“WinBUGS.”</span> Available: <a href="http://www.openbugs.net/w/FrontPage">http://www.openbugs.net/w/FrontPage</a></div>
</div>
</div></section></div> ]]></description>
  <category>GSoC</category>
  <category>Blog</category>
  <guid>https://turinglang.org/news/posts/2025-09-01-GSoC-Report-DoodleBUGS/</guid>
  <pubDate>Mon, 01 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 11</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-07-25-newsletter-11/</link>
  <description><![CDATA[ 





<p><strong>Libtask and Turing.jl</strong></p>
<p>The new versions of Libtask and AdvancedPS have now been integrated into Turing.jl proper. You shouldn’t see any changes, except that particle MCMC methods will now run a lot faster!</p>
<p>(Do note that these won’t work on Julia 1.12 just yet as it is somewhat tightly coupled to Julia internals; we’re working on a fix but if you really want to use Turing on 1.12 right now you will have to stick to Turing ≤ 0.39.6.)</p>
<p><strong>Progress bars</strong></p>
<p>AbstractMCMC 5.7 is released with the new progress bars! By default you get a single progress bar (but with more frequent updates). You need to opt-in to per-chain progress bars with <code>sample(...; progress=:perchain)</code></p>
<p><strong>ADTests categories</strong></p>
<p><a href="https://turinglang.org/ADTests/">The list of models has been split up</a> into different sections to make it a bit easier to read. I’m keen to add more examples of integrations with other packages — if you have a Turing model that uses functionality from a different package inside it, please do get in touch with an example! (I’ll be adding things like DifferentialEquations, HiddenMarkovModels, and AbstractGPs soon, since those are already in our docs)</p>
<p><strong>Community meetings</strong></p>
<p>The Turing.jl developer team usually meet once every week; we’re thinking of opening some of these meetings to be public (perhaps once a month) and would like to gauge whether there’s any interest in this. Our current thinking is that these meetings would be something along the lines of:</p>
<ul>
<li>3 guests with 1 topic each, 10 minutes each: these would be user-submitted and could really be anything you wanted to talk about, e.g.&nbsp;how to write a model, what samplers to use, … And basic stuff is totally fine as that means more people get to learn how to do Bayesian modelling :)</li>
<li>10 minutes from us on “where Turing is going”</li>
<li>20 minutes free Q&amp;A</li>
</ul>
<p>If you would be interested in attending such a meeting or bringing along a topic, do <a href="https://julialang.slack.com/archives/CCYDC34A0/p1753712389947349">let us know on Slack</a>!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-07-25-newsletter-11/</guid>
  <pubDate>Fri, 25 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 10</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-07-11-newsletter-10/</link>
  <description><![CDATA[ 





<p><strong>LKJCholesky</strong></p>
<p>Sampling <code>LKJCholesky</code> with HMC/NUTS has, until now, failed because of numerical instabilities (you’d usually get a <code>DomainError</code> somewhere). Bijectors.jl has gotten a couple of fixes (<a href="https://github.com/TuringLang/Bijectors.jl/pull/356">here</a> and <a href="https://github.com/TuringLang/Bijectors.jl/pull/357">here</a>, just released v0.15.8 today that contains both of these) that should fix this, hopefully once and for all! (There are still some issues with <code>LKJ</code> itself, see <a href="https://github.com/TuringLang/Bijectors.jl/pull/395">this PR</a>. But now with <code>LKJCholesky</code> working there is less need for <code>LKJ</code> :))</p>
<p><strong>Multiple-chain progress bars</strong></p>
<p>Not released yet, but you might like to see <a href="https://github.com/TuringLang/AbstractMCMC.jl/pull/168">this PR (and the videos therein!)</a> which, if merged, will provide more detailed progress bars when sampling with <code>MCMCThreads()</code> or <code>MCMCDistributed()</code>. Currently, the default is that for 10 chains or fewer you’ll get one progress bar per chain; above that there’ll just be one overall progress bar, but it’ll update more than once per chain. That’s customisable, and if you think the default should be different feel free to drop a line!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-07-11-newsletter-10/</guid>
  <pubDate>Fri, 11 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 9</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-06-20-newsletter-9/</link>
  <description><![CDATA[ 





<p><strong>Google Summer of Code</strong></p>
<p>We will have two GSoC students this year working with us: their projects are both focused on JuliaBUGS.jl, one on developing a graphical interface in a web browser, and another on an R interface. We (re?-)welcome Mateus and Shravan — if you see them around do say hi 🙂</p>
<p><strong>TuringGLM.jl</strong></p>
<p>We’ve been thinking about putting in some work on <a href="https://github.com/TuringLang/TuringGLM.jl">TuringGLM.jl</a>, which allows one to create Turing models using formula syntax (similar to that in brms, lme4 or bambi). There are (as always) plenty of things for us to work through, but if you’ve used this and would like to let us know about what you’d like to see in it, feel free to message or open an issue on the repository!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-06-20-newsletter-9/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 8</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-06-06-newsletter-8/</link>
  <description><![CDATA[ 





<p>The major update this week is the release of Turing.jl v0.39. The biggest change is the update to AdvancedVI 0.4, and corresponding changes in Turing’s VI interface. We’re still working on bringing all the docs up to date, but here’s what you can expect from the new version:</p>
<ul>
<li>location-scale families with dense scale matrices,</li>
<li>parameter-free stochastic optimization algorithms like <code>DoG</code> and <code>DoWG</code>,</li>
<li>proximal operators for stable optimization,</li>
<li>the sticking-the-landing control variate for faster convergence, and</li>
<li>the score gradient estimator for non-differentiable targets.</li>
</ul>
<p>There are some other small changes to do with imports and exports. The brief summary is: <code>@addlogprob!</code> is now formally exported. There are a bunch of other, unexported, things where you may need to change from <code>Turing.foo</code> to <code>DynamicPPL.foo</code> – although this probably only applies if you were using DynamicPPL internals. If you have any issues with these please feel free to get in touch.</p>
<p>Apart from this, we have also released AdvancedHMC.jl 0.8! Breaking changes include: - if you are relying the internal <code>transition</code> to make an MCMC transition from phase point <code>z</code> using trajectory <code>τ</code> (or HMCKernel <code>κ</code>) with Hamiltonian <code>h</code>, please note the signature has changed. The usage should now always be <code>transition(h, τ, z)</code> or <code>transition(h, κ, z)</code>. - HMC sampling requires appropriate step size for the Leapfrog integration, as the chosen step size directly affects the numerical stability of the integration process. While AdvancedHMC.jl provides <code>find_good_stepsize</code> to find a suitable step size during HMC sampling, it didn’t support manual step size specification, which caused unnecessary searching. Now <code>initial_step_size</code> can be specified as a keyword in <code>find_good_stepsize</code> if you want more control of the step size selection process.</p>
<p>And finally, we have a few new examples of normalising flows in the NormalizingFlows.jl library: https://github.com/TuringLang/NormalizingFlows.jl/tree/main/example</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-06-06-newsletter-8/</guid>
  <pubDate>Fri, 06 Jun 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 7</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-05-23-newsletter-7/</link>
  <description><![CDATA[ 





<p><strong>MCMCChains@7</strong></p>
<p>There’s a new major version of <a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains.jl</a>. From a user point of view, the main difference is that summary statistics and quantiles aren’t automatically calculated by default (so, printing a <code>Chains</code> object in a REPL will only show the parameter names and sizes). To get the summary statistics and quantiles you will have to run <code>describe(chain)</code>. The main reason for this is because the summary stats would often take quite a while to compute — if you wish to preserve the old behaviour you can stick to MCMCChains@6.</p>
<p><strong>JuliaBUGS <code>@model</code></strong></p>
<p><a href="https://github.com/TuringLang/JuliaBUGS.jl">JuliaBUGS.jl</a> recently implemented a <code>@model</code> macro which, in terms of its syntax, looks somewhat similar to Turing.jl’s own macro, but under the hood constructs a BUGS model. Perhaps of interest is the way that parameters are initialised using <code>@parameters struct ... end</code>; this currently helps to initialise all parameter values to placeholders, and offers an alternative to explicitly specifying this with NamedTuples or arrays. This hasn’t yet been released but for more information and a demonstration, there’s <a href="https://github.com/TuringLang/JuliaBUGS.jl/blob/main/docs/src/julia_syntax.md">a documentation page</a> that describes the design of this macro. The existing <code>@bugs</code> macro will still be retained.</p>
<p><strong>Libtask</strong></p>
<p><a href="https://github.com/TuringLang/Libtask.jl">Libtask.jl</a>, the library that Turing’s particle Gibbs sampler is built on, was recently rewritten for its core parts by Will Tebbutt (<a href="https://github.com/TuringLang/Libtask.jl/pull/179">#179</a>. Libtask implements copyable, resumable tasks (coroutines) in pure Julia, and the new version is much faster and better documented. The new implementation is based on source code transformations, using tools and techniques from <a href="https://github.com/chalk-lab/Mooncake.jl">Mooncake.jl</a>. <a href="https://github.com/TuringLang/AdvancedPS.jl/pull/114">Work</a> is ongoing to adapt AdvancedPS.jl to work with the new Libtask version, and once that is done we should expect a performance boost for Turing’s particle Gibbs sampler. We’ll let you know once that’s out.</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-05-23-newsletter-7/</guid>
  <pubDate>Fri, 23 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 6</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-05-09-newsletter-6/</link>
  <description><![CDATA[ 





<p>Turing v0.38 has just been released and incorporates the changes from DynamicPPL which were mentioned <a href="../../../news/posts/2025-04-25-newsletter-5">in the last newsletter</a>. It also contains a fix for the Gibbs sampler, so that you can now specify arbitrary VarNames for each sampler (previously, you could only specify single-symbol VarNames). For example, you can now specify the <code>a.x</code> and <code>b.x</code> VarNames here:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>()</span>
<span id="cb1-2">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Normal</span>()</span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb1-4"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">outer</span>()</span>
<span id="cb1-5">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">to_submodel</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>())</span>
<span id="cb1-6">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">to_submodel</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>())</span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">outer</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Gibbs</span>(<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@varname</span>(a.x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">MH</span>(), <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@varname</span>(b.x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">MH</span>()), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span></code></pre></div>
<p>It is theoretically possible that this will be slow for VarNames that involve indexing (e.g.&nbsp;<code>x[1]</code>), although we don’t have an example of this yet. If you find anything you think should be faster, let us know.</p>
<p>One other minor point: <a href="https://turinglang.org/ADTests/">on ADTests</a> you can now hover over a model name to see its definition.</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-05-09-newsletter-6/</guid>
  <pubDate>Fri, 09 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 5</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-04-25-newsletter-5/</link>
  <description><![CDATA[ 





<p><strong>DynamicPPL 0.36</strong></p>
<p>A new minor version of DynamicPPL brings with it a few changes especially to the behaviour of submodels. These have not yet percolated up to Turing.jl, but will soon be. Firstly, prefixing behaviour is changed: consider these models</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>()</span>
<span id="cb1-2">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Normal</span>()</span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb1-4"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">outer</span>()</span>
<span id="cb1-5">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>]</span>
<span id="cb1-6">    a[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">to_submodel</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>())</span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span></code></pre></div>
<p>If you ran this model, you would find that the single random variable was called <code>a[1].x</code> — but this isn’t the <code>x</code> field of the <code>1</code>st element of <code>a</code>, it’s actually a variable whose name is literally just <code>Symbol("a[1].x")</code>. DynamicPPL changes this behaviour such that the variable is correctly recognised as the <code>x</code> field of the <code>1</code>st element of <code>a</code>. This means that if you are trying to, for example, condition on the variable, you can do:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">outer</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> (<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@varname</span>(a[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>)</span></code></pre></div>
<p>On the topic of conditioning, you can now also correctly condition or fix variables in a model before using it as a submodel, as this example demonstrates:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>()</span>
<span id="cb3-2">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Normal</span>()</span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb3-4"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@model</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">outer</span>()</span>
<span id="cb3-5">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">to_submodel</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> (<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@varname</span>(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span></code></pre></div>
<p>Previously, if you wanted to do this, you would have to condition on <code>@varname(a.x)</code>, meaning that you’d need to know the prefix before conditioning it. The current system allows for more modular construction of nested models.</p>
<p>For more complete details, please see <a href="https://github.com/TuringLang/DynamicPPL.jl/releases/tag/v0.36.0">the release notes</a>.</p>
<p><strong>TuringBenchmarking.jl</strong></p>
<p>DynamicPPL 0.36 also brings new functionality that can be used for testing and benchmarking automatic differentiation on Turing models. This is what powers the <a href="https://turinglang.org/ADTests/">ADTests table</a>, which we shared last time round. (Psst — there are more examples now than before!)</p>
<p>For more information, see the docstring of <code>DynamicPPL.TestUtils.AD.run_ad</code> in <a href="https://turinglang.org/DynamicPPL.jl/stable/api/#DynamicPPL.TestUtils.AD.run_ad">the DynamicPPL docs</a>.</p>
<p>As a corollary of this, the AD benchmarking functionalities in TuringBenchmarking.jl are not really needed anymore. If you are using this package, we recommend that you switch over to use the functionality that’s directly built into DynamicPPL.</p>
<p><strong>AdvancedHMC compatibility with ComponentArrays</strong></p>
<p>AdvancedHMC had a fairly long-standing issue where it couldn’t always be used with ComponentArrays as the position / momentum. This has now been fixed; you can take a look at <a href="https://github.com/TuringLang/AdvancedHMC.jl/blob/459ebb8a10cc1bc7dbbc27ed79afa796c607697a/test/hamiltonian.jl#L77-L100">the test suite</a> to see examples of how they can be used together.</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-04-25-newsletter-5/</guid>
  <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 4</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-04-11-newsletter-4/</link>
  <description><![CDATA[ 





<p><strong>Have you used Turing.jl?</strong></p>
<p>Given that you’re reading this, we hope so! We’re currently putting together a list of papers and other outputs (e.g.&nbsp;tutorials, presentations, …) which make use of Turing.jl. We’d love to have more examples, if you have any, please do get in touch (feel free to message me and I can forward it). Thank you!</p>
<p><strong>State of the AD</strong></p>
<p>Over the last few weeks we’ve been putting together a little project that tabulates the performance of different AD backends on a variety of Turing.jl models, and we’re now quite excited to share it: https://turinglang.org/ADTests/ This will hopefully help to answer the perennial question of whether you should stick with good old ForwardDiff, or whether you should try something else. Do note that (as of the time of writing) this table is still in alpha stage and there are a lot of details that have yet to be ironed out :slightly_smiling_face: However, suggestions are always welcome!</p>
<p><strong>JuliaBUGS.jl</strong></p>
<p>The BUGS (Bayesian inference Using Gibbs Sampling) language provides a declarative way to specify complex Bayesian statistical models. For years, implementations like WinBUGS, OpenBUGS, and JAGS have been widely used tools for researchers applying these models. JuliaBUGS.jl is a modern implementation of the BUGS language, aiming for full backwards compatibility with standard BUGS models, while also offering improved interoperability with the Julia ecosystem. (For details and examples of BUGS syntax, check out <a href="https://turinglang.org/JuliaBUGS.jl/dev/example/">the JuliaBUGS documentation</a>.)</p>
<p><a href="https://github.com/TuringLang/JuliaBUGS.jl/pull/278/">A recent experimental update</a> introduces significant performance improvements in JuliaBUGS: instead of relying solely on the previous graph-based approach, JuliaBUGS can now directly generate Julia code to compute the model’s log-density. This code generation technique can yield &gt;10x speedups compared to the graph-based method. Currently, this provides the most benefit for models with linear or hierarchical structures; support for state space models is planned for a future update.</p>
<p>To use it, run this after compiling your model:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1">JuliaBUGS.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set_evaluation_mode</span>(your_model, JuliaBUGS.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">UseGeneratedLogDensityFunction</span>())</span></code></pre></div>
<p>We would love for you to test out this new functionality! If you have any feedback, please do feel free to open a GitHub issue or discussion.</p>
<p><strong>Even more advanced HMC</strong></p>
<p>Lastly, we have a paper of our own to share on Hamiltonian Monte Carlo methods!</p>
<ul>
<li>Xu, K., &amp; Ge, H. (2024). Practical Hamiltonian Monte Carlo on Riemannian Manifolds via Relativity Theory. <em>Forty-First International Conference on Machine Learning.</em> https://openreview.net/pdf?id=Et8Pk97u4u and https://icml.cc/virtual/2024/poster/34558</li>
</ul>
<p>We will be looking to integrate these methods into Turing.jl in the future.</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-04-11-newsletter-4/</guid>
  <pubDate>Fri, 11 Apr 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 3</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-03-28-newsletter-3/</link>
  <description><![CDATA[ 





<p><strong>Turing v0.37</strong></p>
<p>We’ve now released v0.37 of Turing. This includes a lot of new functionality from DynamicPPL 0.35, including the new (simplified) <code>.~</code> . It also cleans up the list of exported identifiers, and most notably, if you were using things from DynamicPPL, you will now also need to <code>import DynamicPPL</code> (or <code>using</code>).</p>
<p>More generally, it’s likely that from now on our releases will involve larger changes because we are aggregating more changes into a single minor version. We are, however, also committed to providing thorough release notes that will help users and library authors upgrade more easily! Release notes will be available on GitHub, and you can see the notes for <a href="https://github.com/TuringLang/Turing.jl/releases/">Turing 0.37</a> and <a href="https://github.com/TuringLang/DynamicPPL.jl/releases">DynamicPPL 0.35</a> here. If you have any trouble upgrading, just drop us a note.</p>
<p><strong>AD backend testing</strong></p>
<p>Right now we test a series of DynamicPPL models with several AD backends. It’s rather ad-hoc and we are currently drafting a more formal interface for testing AD backends with Turing models. It’s still early days but if you are an AD package developer and want to know what this means for integration with Turing, get in touch (easiest way: <a href="https://julialang.slack.com/team/U07DBR7C2LD">ping Penny on Slack</a>) 🙂</p>
<p><strong>Unified interface for optimisation algorithms</strong></p>
<p>There’s <a href="https://github.com/TuringLang/Turing.jl/issues/2509">an ongoing discussion about unifying the interface</a> for MAP/MLE point estimates and variational inference (and potentially even MCMC). If you use more than one of these methods and have thoughts on what you’d like from an interface, we’d be very happy to hear from you!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-03-28-newsletter-3/</guid>
  <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 2</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-03-14-newsletter-2/</link>
  <description><![CDATA[ 





<p><strong>DynamicPPL benchmarking</strong></p>
<p>DynamicPPL.jl now has a set of benchmarks that are run on GitHub Actions! We measure how long it takes to evaluate a small selection of models and also to run AD on them. If you think that there are specific models / features that we should add to the benchmarks, please feel free to <a href="https://github.com/TuringLang/DynamicPPL.jl/issues/new">create an issue</a> and let us know.</p>
<p>Separately, we are planning to merge the benchmarking utilities in <a href="https://github.com/TuringLang/TuringBenchmarking.jl">TuringBenchmarking.jl</a> into DynamicPPL itself. There might be a little bit of API shake-up as part of this, but it’s for the better as it’ll allow the benchmarking code to more easily stay in sync with DynamicPPL — allowing us to catch performance regressions in PRs.</p>
<p><strong>SSMProblems</strong></p>
<p>The SSMProblems.jl and GeneralisedFilters.jl packages have now been merged into a single repository: <a href="https://github.com/TuringLang/SSMProblems.jl">https://github.com/TuringLang/SSMProblems.jl</a>. This won’t affect you if you are using the packages from the Julia General registry, but if you’re looking to develop off the main branch you may have to use a different URL, or specify a subdirectory in <code>Pkg.add</code>.</p>
<p><strong>Smaller bits</strong></p>
<p>Other code changes that have been merged:</p>
<ul>
<li>Some old code in AdvancedHMC.jl has been cleaned up quite a bit. See the <a href="https://github.com/TuringLang/AdvancedHMC.jl/releases/tag/v0.7.0">0.7.0 release</a> for more information.</li>
<li>Turing’s Gibbs sampler <a href="https://github.com/TuringLang/Turing.jl/pull/2502">now supports warmup steps properly</a>. We’re still thinking about how to properly encode the scenario where different sub-samplers have different numbers of warmup steps, if you have any ideas, do get in touch on that PR.</li>
<li>We are going to formally remove support for Zygote as an AD backend. We don’t test it thoroughly in Turing’s test suite. You can of course still use Zygote yourself, simply load <code>ADTypes.AutoZygote()</code> —&nbsp;although we can’t guarantee that we will fix any bugs that arise.</li>
</ul>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-03-14-newsletter-2/</guid>
  <pubDate>Fri, 14 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing.jl Newsletter 1</title>
  <dc:creator>The TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2025-02-28-newsletter-1/</link>
  <description><![CDATA[ 





<p>Welcome to the inaugural issue of the Turing.jl newsletter!</p>
<p><strong>What is this?!</strong></p>
<p>Hi everyone! We (the Turing.jl team) are starting a fortnightly series of updates on what we’ve been up to and what’s in the works. We hope that this will provide you (our users) with some insight into the direction of the Turing ecosystem, and we’d also love for you to chip in with your thoughts if you have any.</p>
<p>You can keep up with the newsletter either on this website, on the <a href="https://julialang.slack.com/archives/CCYDC34A0">#turing channel in Julia Slack</a>, or by subscribing to <a href="https://github.com/TuringLang/Turing.jl/issues/2498">our issue on GitHub</a>. We might post to other places too (like Discourse), this is still in the works!</p>
<p><strong>New Turing behaviour, especially <code>.~</code></strong></p>
<p>Recently we have been focused on reworking a number of internal data structures in DynamicPPL.jl (this is the package that allows you to define models). We haven’t released this yet but you might be interested to see <a href="https://github.com/TuringLang/DynamicPPL.jl/blob/e6a42dd6b410d4ed60d853222c297a391cffe6d1/HISTORY.md">the changelog on GitHub</a>. The main user-facing changes here are the simplification of broadcasted tilde <code>.~</code> , which we previously <a href="https://julialang.slack.com/archives/CCYDC34A0/p1738580415136749">posted about on Slack here</a>. We also fixed a bug where the prefixes of nested submodels were applied in the wrong order.</p>
<p><strong>DifferentiationInterface migration</strong></p>
<p>From a developer perspective, we have now fully switched over to DifferentiationInterface.jl for automatic differentiation of models occurs. This work of course couldn’t have been possible without Guillaume Dalle’s work on DI itself and also his help with integrating it into DynamicPPL. This also paves the way for a long-standing goal of Turing, which is to expose a series of AD testing utilities that will allow AD package developers to test against a fixed set of models — this will allow us to formalise the idea of Turing being ‘compatible’ with a given AD package.</p>
<p><strong>The plan for submodels</strong></p>
<p>We have been discussing for a while now about how best to fully implement submodels (i.e.&nbsp;be able to treat submodels like distributions in the sense that we can sample from them, and also condition models on values obtained from submodels). There is currently a proposal which we’ve <a href="https://github.com/TuringLang/Turing.jl/issues/2485">written up on GitHub</a>, and goes into more depth about what we’d like to see and the underlying syntax. If this is a Turing feature that you use, do feel free to let us know what you think.</p>
<p><strong>Turing.jl is now published (again!)</strong></p>
<p>We recently published a new paper with a high-level overview of Turing.jl’s features and implementation. Check it out!<br>
Fjelde, T. E., Xu, K., Widmann, D., Tarek, M., Pfiffer, C., Trapp, M., Axen, S. D., Sun, X., Hauru, M., Yong, P., Tebbutt, W., Ghahramani, Z., &amp; Ge, H. (2024). Turing.jl: A General-Purpose Probabilistic Programming Language. <em>ACM Transactions on Probabilistic Machine Learning</em>, 1(1). (<a href="https://dl.acm.org/doi/10.1145/3711897">link</a>)</p>
<p>We have also published in the conference proceedings of the workshop on Languages for Inference (LAFI), which was held as part of POPL 2025:<br>
Tim Hargreaves, Qing Li, Charles Knipp, Frederic Wantiez, Simon J. Godsill, Hong Ge. State Space Model Programming in Turing.jl. <em>The Languages for Inference (LAFI) workshop</em>, 2025. (<a href="https://popl25.sigplan.org/details/lafi-2025/11/State-Space-Model-Programming-in-Turing-jl">link</a>)</p>
<p><strong>Looking for Google Summer of Code students</strong></p>
<p>We are keen to take students for <a href="https://julialang.org/jsoc/gsoc/turing/">GSoC in 2025</a>! If you are interested in working on a Python/R interface to <a href="https://github.com/TuringLang/JuliaBUGS.jl">JuliaBUGS</a>, or making some improvements to <a href="https://github.com/JasonPekos/TuringPosteriorDB.jl">TuringPosteriorDB</a>, do get in touch.</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Newsletter</category>
  <guid>https://turinglang.org/news/posts/2025-02-28-newsletter-1/</guid>
  <pubDate>Fri, 28 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Google Summer of Code 2022</title>
  <dc:creator>Kai Xu</dc:creator>
  <dc:creator>the TuringLang team</dc:creator>
  <link>https://turinglang.org/news/posts/2022-02-17-gsoc/</link>
  <description><![CDATA[ 





<p>It is another year of the <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> time, and we have compiled an updated list of exciting Turing projects! Projects that the Turing team would be interested in working with students on over the summer are listed below. This information is also cross-posted at <a href="https://julialang.org/jsoc/gsoc/turing/">Julia’s Turing project page</a>.</p>
<p>If you are interested in exploring any of these projects or have any questions, please reach out to the listed project mentors. You can find their contact information at <a href="https://turinglang.org/stable/team">turinglang.org/team</a>.</p>
<section id="more-real-world-bayesian-models-in-turing-julia" class="level2">
<h2 class="anchored" data-anchor-id="more-real-world-bayesian-models-in-turing-julia">More real-world Bayesian models in Turing / Julia</h2>
<p><strong>Mentors</strong>: Kai Xu, Tor E. Fjelde, Hong Ge</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Project length</strong>: 175 hrs or 350 hrs</p>
<p><strong>Description</strong>: There are many real-world Bayesian models out there, and they deserve a Turing / Julia implementation.</p>
<p>Examples include but not limited to - Forecasting (<a href="https://facebook.github.io/prophet/">Prophet</a>, <a href="https://github.com/facebook/prophet/tree/main/examples">datasets</a>) - Recommender system (<a href="http://www.cs.utoronto.ca/~amnih/papers/pmf.pdf">probabilistic matrix factorisation</a>, <a href="https://grouplens.org/datasets/movielens/">dataset</a>) - Ranking (<a href="https://en.wikipedia.org/wiki/TrueSkill">TrueSkill</a>, <a href="https://github.com/dotnet/mbmlbook/tree/main/src/3.%20Meeting%20Your%20Match/Data">dataset</a>) - Bayesian revenue estimation (<a href="https://www.smartly.io/blog/tutorial-how-we-productized-bayesian-revenue-estimation-with-stan">example</a>) - Political forecasting model (<a href="https://github.com/sjwild/Canandian_Election_2021">example</a>) - Topic mining (latent Dirichlet allocation and new variants) - Multiple Annotators/Combining Unreliable Observations (Dawid and Skene, 1979)</p>
<p>For each model, we would consider the following tasks as part of a GSoC project: - Correctness test: correctness of the implementation can be tested by doing inference for prior samples, for which we know the ground truth latent variables. - Performance benchmark: this includes (i) time per MCMC step and (ii) time per effective sample; if the model is differentiable, a further break-down of (i) into (i.1) time per forward pass and (i.2) time per gradient pass are needed. - Real-world results: if available, the final step is to apply the model to a real-world dataset; if such an experiment has been done in the literature, consistency of inference results needs to be checked</p>
</section>
<section id="improving-the-integration-between-turing-and-turings-mcmc-inference-packages" class="level2">
<h2 class="anchored" data-anchor-id="improving-the-integration-between-turing-and-turings-mcmc-inference-packages">Improving the integration between Turing and Turing’s MCMC inference packages</h2>
<p><strong>Mentors</strong>: Cameron Pfiffer, Mohamed Tarek, David Widmann</p>
<p><strong>Project difficulty</strong>: Easy</p>
<p><strong>Project length</strong>: 175 hrs</p>
<p><strong>Description</strong>: Turing.jl is based on a set of inference packages maintained by the TuringLang group. This project is about making use of improvements in DynamicPPL to create a generic integration between Turing.jl and the AbstractMCMC.jl sampling API. The ultimate goal is to remove or substantially reduce algorithm-specific glue code inside Turing.jl. The project would also involve improving data structures for storing model parameters in DynamicPPL.</p>
</section>
<section id="directed-graphical-model-support-for-the-abstract-probabilistic-programming-library" class="level2">
<h2 class="anchored" data-anchor-id="directed-graphical-model-support-for-the-abstract-probabilistic-programming-library">Directed-graphical model support for the abstract probabilistic programming library</h2>
<p><strong>Mentors</strong>: Philipp Gabler, Hong Ge</p>
<p><strong>Project difficulty</strong>: Hard</p>
<p><strong>Project length</strong>: 350 hrs</p>
<p><strong>Description</strong>: We want to have a very light-weight representation of probabilistic models of static graphs (similar to BUGS), which can serve as a representation target of other front-end DSLs or be dynamically built. The representation should consist of the model and node representations (stochastic and deterministic, perhaps hyperparameters) and conform to the AbstractPPL model interface, with basic functions (evaluation of density, sampling, conditioning; at later stages some static analysis like extraction of Markov blankets). The model should also contain the state of the variables and implement the AbstractPPL trace interface (dictionary functions, querying of variable names). The result should be able to work with existing sampling packages through the abstract interfaces.</p>
</section>
<section id="a-modular-tape-caching-mechanism-for-reversediff" class="level2">
<h2 class="anchored" data-anchor-id="a-modular-tape-caching-mechanism-for-reversediff">A modular tape caching mechanism for ReverseDiff</h2>
<p><strong>Mentors</strong>: Qingliang Zhuo, Mohamed Tarek</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Project length</strong>: 175 hrs</p>
<p><strong>Description</strong>: Tape caching often leads to significant performance improvements for gradient-based sampling algorithms (e.g.&nbsp;HMC/NUTS). Tape caching is only possible at the complete computational level for ReverseDiff at the moment. This project is about implementing a more modular, i.e.&nbsp;function-as-a-caching-barrier, tape caching mechanism for ReverseDiff.jl.</p>
</section>
<section id="benchmarking-improving-performance-of-the-juliagaussianprocesses-libraries" class="level2">
<h2 class="anchored" data-anchor-id="benchmarking-improving-performance-of-the-juliagaussianprocesses-libraries">Benchmarking &amp; improving performance of the JuliaGaussianProcesses libraries</h2>
<p><strong>Mentors</strong>: Theo Galy-Fajou, Will Tebbutt, ST John</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Project length</strong>: 350 hrs</p>
<p><strong>Description</strong>: Although KernelFunctions.jl has extensive correctness testing, our performance testing is lacking. This project aims to resolve this, and resolve performance issues wherever they are found. The student would first need to extend our existing benchmarking coverage, and debug any obvious performance problems. The next phase of the work would be to construct end-to-end examples of KernelFunctions being used in practice, profile them to determine where performance problems lie, and fix them.</p>
</section>
<section id="iterative-methods-for-inference-in-gaussian-processes" class="level2">
<h2 class="anchored" data-anchor-id="iterative-methods-for-inference-in-gaussian-processes">Iterative methods for inference in Gaussian Processes</h2>
<p><strong>Mentors</strong>: Will Tebbutt, S. T. John, Ross Viljoen</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Project length</strong>: 175 hrs</p>
<p><strong>Description</strong>: There has recently been quite a bit of work on inference methods for GPs that use iterative methods rather than the Cholesky factorisation. They look quite promising, but no one has implemented any of these within the Julia GP ecosystem yet, but they should fit nicely within the AbstractGPs framework. If you’re interested in improving the GP ecosystem in Julia, this project might be for you!</p>
</section>
<section id="approximate-inference-methods-for-non-gaussian-likelihoods-in-gaussian-processes" class="level2">
<h2 class="anchored" data-anchor-id="approximate-inference-methods-for-non-gaussian-likelihoods-in-gaussian-processes">Approximate inference methods for non-Gaussian likelihoods in Gaussian Processes</h2>
<p><strong>Mentors</strong>: S. T. John, Ross Viljoen, Theo Galy-Fajou</p>
<p><strong>Project difficulty</strong>: Hard</p>
<p><strong>Project length</strong>: 350 hrs</p>
<p><strong>Description</strong>: Adding <a href="https://github.com/JuliaGaussianProcesses/JuliaGaussianProcesses.github.io/discussions/5#discussioncomment-1627101">approximate inference</a> methods for non-Gaussian likelihoods which are available in other GP packages but not yet within JuliaGPs. The project would start by determining which approximate inference method(s) to implement—there’s lots to do, and we’re happy to work with a student on whichever method they are most interested in, or to suggest one if they have no strong preference.</p>
</section>
<section id="gpu-integration-in-the-juliagps-ecosystem" class="level2">
<h2 class="anchored" data-anchor-id="gpu-integration-in-the-juliagps-ecosystem">GPU integration in the JuliaGPs ecosystem</h2>
<p><strong>Mentors</strong>: Ross Viljoen, Theo Galy-Fajou, Will Tebbutt</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Project length</strong>: 350 hrs</p>
<p><strong>Description</strong>: This would involve first ensuring that common models are able to run fully on the GPU, then identifying and improving GPU-specific performance bottlenecks. This would begin by implementing a limited end-to-end example involving a GP with a standard kernel, and profiling it to debug any substantial performance bottlenecks. From there, support for a wider range of the functionality available in KernelFunctions.jl and AbstractGPs.jl can be added. Stretch goal: extension of GPU support to some functionality in ApproximateGPs.jl.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Blog</category>
  <category>GSoC</category>
  <guid>https://turinglang.org/news/posts/2022-02-17-gsoc/</guid>
  <pubDate>Thu, 17 Feb 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Google Summer of Code 2021</title>
  <dc:creator>Cameron Pfiffer</dc:creator>
  <link>https://turinglang.org/news/posts/2021-02-04-gsoc/</link>
  <description><![CDATA[ 





<p>It’s about time for us to start thinking about projects we’d like to see at Turing.jl for the <a href="https://summerofcode.withgoogle.com/">Google Summer of Code 2021</a>! Below is a list of projects the Turing team would be interested in working with students on for the summer.</p>
<p>If you are interested in exploring any of these projects, please reach out to the listed project mentors. You can find their contact information at <a href="https://turinglang.org/stable/team">turinglang.org/team</a>.</p>
<section id="mcmcchains-improvements" class="level1">
<h1>MCMCChains improvements</h1>
<p><strong>Mentors</strong>: Cameron Pfiffer, Hong Ge</p>
<p><strong>Project difficulty</strong>: Easy</p>
<p><strong>Description</strong>: MCMCChains is a key component of the Turing.jl ecosystem. It is the package that determines how to analyze and store MCMC samples provided by packages like Turing. It’s also used outside of Turing.</p>
<p>For this project, a student might improve the performance of the various statistical functions provided by MCMCChains, changing the back end to use a data storage format that maintains the shape of parameter samples, or improve the general plotting functionality of the package.</p>
<p>There’s lots of fun little things to do for MCMCChains. Check out this <a href="https://github.com/TuringLang/MCMCChains.jl/issues/246">meta-issue</a> for more details and discussions.</p>
</section>
<section id="particle-filtering-methods" class="level1">
<h1>Particle filtering methods</h1>
<p><strong>Mentors</strong>: Hong Ge, Cameron Pfiffer</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Description</strong>: Turing’s support for particle sampling methods is slowing being improved with the addition of <a href="https://github.com/TuringLang/AdvancedPS.jl">AdvancedPS.jl</a>. If you’re interested in implementing or improving particle sampling methods, this is a great project for you!</p>
</section>
<section id="nested-sampling" class="level1">
<h1>Nested Sampling</h1>
<p><strong>Mentors</strong>: Miles Lucas, Cameron Pfiffer, Hong Ge</p>
<p><strong>Project difficulty</strong>: Hard</p>
<p><strong>Description</strong>: <a href="https://github.com/TuringLang/NestedSamplers.jl">NestedSamplers.jl</a> is an excellent package which implements nested sampling methods. As of yet, it is not connected to Turing.jl. For this project, a student would connect the NestedSamplers.jl library to Turing.jl.</p>
</section>
<section id="gpu-acceleration" class="level1">
<h1>GPU acceleration</h1>
<p><strong>Mentors</strong>: Mohamed Tarek, Hong Ge, Kai Xu, Tor Fjelde</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Description</strong>: Turing’s native GPU support is limited in that the Metropolis-Hastings and HMC samplers do not implement GPU sampling methods. This can and should be done – GPU methods are awesome! If you are interested with working on parallelism and GPUs, this project is for you.</p>
<p>Students will work with the code at <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH</a> or <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC</a>, depending on their interests.</p>
</section>
<section id="documentation-and-tutorial-improvements" class="level1">
<h1>Documentation and tutorial improvements</h1>
<p><strong>Mentors</strong>: Cameron Pfiffer, Martin Trapp</p>
<p><strong>Project difficulty</strong>: Easy</p>
<p><strong>Description</strong>: Turing’s documentation and tutorials need a bit of an overhaul. Turing has changed significantly since the last time the documentation was written, and it’s beginning to show. Students would use their knowledge of probabilistic programming languages and Turing to shore-up or rewrite documentation and tutorials.</p>
</section>
<section id="iterative-methods-for-inference-in-gaussian-processes" class="level1">
<h1>Iterative Methods for Inference in Gaussian Processes</h1>
<p><strong>Mentors</strong>: Will Tebbutt, S. T. John, Theo Galy-Fajou</p>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Description</strong>: There has recently been quite a bit of work on inference methods for GPs that use iterative methods rather than the Cholesky factorisation. They look quite promising, but no one has implemented any of these within the Julia GP ecosystem yet, but they should fit nicely within the AbstractGPs framework. If you’re interested in improving the GP ecosystem in Julia, this project might be for you!</p>
</section>
<section id="implement-advanced-variational-gaussian-process-models" class="level1">
<h1>Implement advanced variational Gaussian process models</h1>
<p><strong><em>Mentors</em></strong>: ST John, Will Tebbutt, Theo Galy-Fajou</p>
<p><strong><em>Project difficulty</em></strong>: Easy to Medium</p>
<p><strong><em>Description</em></strong>: Sparse variational Gaussian process models provide the flexibility to scale to large datasets, handle arbitrary (non-conjugate) likelihoods, and to be used as building blocks for composite models such as deep GPs. This project is about making such models more readily available within the Julia GP ecosystem - depending on your interests you can focus on making it easier for end users and providing good tutorials, or on the implementations of these models to give us the same or better performance as with established Python packages such as GPflow, integrating with Flux.jl, etc.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Blog</category>
  <category>GSoC</category>
  <guid>https://turinglang.org/news/posts/2021-02-04-gsoc/</guid>
  <pubDate>Wed, 10 Feb 2021 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Google Summer of Code 2020</title>
  <dc:creator>Cameron Pfiffer</dc:creator>
  <link>https://turinglang.org/news/posts/2020-09-11-gsoc/</link>
  <description><![CDATA[ 





<p>As the 2020 <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> comes to a close, the Turing team thought it would be a good opportunity to reflect on the work that was done by our superb students this summer.</p>
<p><a href="https://github.com/SaranjeetKaur">Saranjeet Kaur</a>’s <a href="https://summerofcode.withgoogle.com/projects/#6567464390885376">project</a> focused primarily on expanding <a href="https://github.com/TuringLang/NestedSamplers.jl">NestedSamplers.jl</a>. NestedSamplers.jl now supports <a href="https://arxiv.org/abs/1506.00171">PolyChord-style</a> nested sampling natively, which is an absolute delight. Saranjeet wrote about this <a href="https://nextjournal.com/Saranjeet-Kaur/extending-nestedsamplersjl">here</a>. She also provided a good tutorial on how to use NestedSamplers.jl <a href="https://nextjournal.com/Saranjeet-Kaur/illustrations-of-use-of-nestedsamplersjl">here</a>. The NestedSamplers.jl integration with Turing is still on-going – integrating new samplers with Turing is one of the more difficult tasks. If you are interested to see the progress on this, check out the relevant <a href="https://github.com/TuringLang/Turing.jl/pull/1333">pull request</a>.</p>
<p><a href="https://github.com/luiarthur">Arthur Lui</a>’s <a href="https://summerofcode.withgoogle.com/projects/#5861616765108224">project</a> was to provide a much-needed set of benchmarks of Bayesian nonparametric models between Turing and other PPLs. Arthur’s work spawned a <a href="https://github.com/luiarthur/TuringBnpBenchmarks">GitHub repository</a> with good practices for benchmarking, as well as three blog posts with some (very cool!) statistics on Turing’s performance:</p>
<ol type="1">
<li><a href="https://luiarthur.github.io/TuringBnpBenchmarks/dpsbgmm">Dirichlet Process Gaussian mixture model via the stick-breaking construction in various PPLs</a></li>
<li><a href="https://luiarthur.github.io/TuringBnpBenchmarks/gp">Gaussian Process Regression Model in various PPLs</a></li>
<li><a href="https://luiarthur.github.io/TuringBnpBenchmarks/gpclassify">Gaussian Process Classification Model in various PPLs</a></li>
</ol>
<p>Finally, <a href="https://github.com/sharanry">Sharan Yalburgi</a> (a returning GSoC student) completed an epic amount of work Turing’s growing suite of <a href="https://summerofcode.withgoogle.com/projects/#5565948129443840">Gaussian process tools</a>. In particular, the GitHub organization <a href="https://github.com/JuliaGaussianProcesses">JuliaGaussianProcesses</a> was founded, and serves as an effort to build a robust Gaussian process framework for the Julia ecosystem. The framework consists of multiple GP related Julia packages:</p>
<ul>
<li><a href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl">KernelFunctions.jl</a> provides kernel functions for GPs as well as efficient AD for these kernels. KernelFunctions.jl also supports multi-output GPs by providing necessary data abstractions and multi-output kernels.</li>
<li><a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl">AbstractGPs.jl</a> defines GP abstractions and provides exact posteriors. It provides support for induced points based GP posteriors and for efficient sequential/online (sparse) GP updates.</li>
<li><a href="https://github.com/JuliaGaussianProcesses/GPLikelihoods.jl">GPLikelihoods.jl</a> defines alternate likelihoods for Non-Gaussian GPs.</li>
<li><a href="https://github.com/JuliaGaussianProcesses/GPMLj.jl">GPMLj.jl</a> provides a Julia interface for <a href="https://github.com/GPflow/GPflow">GPFlow</a>, a GP library written in Python using TensorFlow.</li>
</ul>
<p>Special thanks to our three GSoC students for this summer, who all did excellent work. Additional thanks to Google for supporting open source software development and the Julia language!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Blog</category>
  <category>GSoC</category>
  <guid>https://turinglang.org/news/posts/2020-09-11-gsoc/</guid>
  <pubDate>Fri, 11 Sep 2020 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Replication study: Estimating number of infections and impact of NPIs on COVID-19 in European countries (Imperial Report 13)</title>
  <dc:creator>Tor Erlend Fjelde</dc:creator>
  <dc:creator>Mohamed Tarek</dc:creator>
  <dc:creator>Kai Xu</dc:creator>
  <dc:creator>David Widmann</dc:creator>
  <dc:creator>Martin Trapp</dc:creator>
  <dc:creator>Cameron Pfiffer</dc:creator>
  <dc:creator>Hong Ge</dc:creator>
  <link>https://turinglang.org/news/posts/2020-05-04-Imperial-Report13-analysis/</link>
  <description><![CDATA[ 





<p>The Turing.jl team is currently exploring possibilities in an attempt to help with the ongoing SARS-CoV-2 crisis. As preparation for this and to get our feet wet, we decided to perform a replication study of the <a href="https://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/report-13-europe-npi-impact/">Imperial Report 13</a>, which attempts to estimate the real number of infections and impact of non-pharmaceutical interventions on COVID-19. In the report, the inference was performed using the probabilistic programming language (PPL) Stan. We have explicated their model and inference in Turing.jl, a Julia-based PPL. We believe the results and analysis of our study are relevant for the public, and for other researchers who are actively working on epidemiological models. To that end, our implementation and results are available <a href="https://github.com/cambridge-mlg/Covid19">here</a>.</p>
<p>In summary, we replicated the Imperial COVID-19 model using Turing.jl. Subsequently, we compared the inference results between Turing and Stan, and our comparison indicates that results are reproducible with two different implementations. In particular, we performed 4 sets of simulations using the Imperial COVID-19 model. The resulting estimates of the expected real number of cases, in contrast to the <em>recorded</em> number of cases, the reproduction number \(R_t\), and the expected number of deaths as a function of time and non-pharmaceutical interventions (NPIs) for each Simulation are shown below.</p>
<!-- {{< include plotly.html >}} -->
<div id="simulation-1-full" class="plotly">

</div>
<script>
 Plotly.d3.json("data/full_prior.json", function(err, fig) {
   Plotly.plot("simulation-1-full", fig.data, fig.layout, {responsive: true});
 });
</script>
<p><strong>Simulation (a):</strong> hypothetical Simulation from the model without data (prior predictive) or non-pharmaceutical interventions. Under the prior assumptions of the Imperial Covid-19 model, there is a very wide range of epidemic progressions with expected cases from almost 0 to 100% of the population over time. The black bar corresponds to the date of the last observation. Note that \(R_t\) has a different time-range than the other plots; following the original report, this shows the 100 days following the country-specific <code>epidemic_start</code> which is defined to be 31 days prior to the first date of 10 cumulative deaths, while the other plots show the last 60 days.</p>
<div id="simulation-2-full" class="plotly">

</div>
<script>
 Plotly.d3.json("data/full_posterior.json", function(err, fig) {
   Plotly.plot("simulation-2-full", fig.data, fig.layout, {responsive: true});
 });
</script>
<p><strong>Simulation (b):</strong> future Simulation with non-pharmaceutical interventions kept in place (posterior predictive). After incorporating the observed infection data, we can see a substantially more refined range of epidemic progression. The reproduction rate estimate lies in the range of 3.5-5.6 before any intervention is introduced. The dotted lines correspond to observations, and the black bar corresponds to the date of the last observation.</p>
<div id="simulation-3-full" class="plotly">

</div>
<script>
 Plotly.d3.json("data/full_counterfactual.json", function(err, fig) {
   Plotly.plot("simulation-3-full", fig.data, fig.layout, {responsive: true});
 });
</script>
<p><strong>Simulation (c):</strong> future Simulation with non-pharmaceutical interventions removed. Now we see the hypothetical scenarios after incorporating infection data, but with non-pharmaceutical interventions removed. This plot looks similar to Simulation (a), but with a more rapid progression of the pandemic since the estimated reproduction rate is bigger than the prior assumptions. The dotted lines correspond to observations, and the black bar corresponds to the date of the last observation.</p>
<div id="simulation-4-full" class="plotly">

</div>
<script>
 Plotly.d3.json("data/full_counterfactual2.json", function(err, fig) {
   Plotly.plot("simulation-4-full", fig.data, fig.layout, {responsive: true});
 });
</script>
<p><strong>Simulation (d):</strong> future Simulation with when <code>lockdown</code> is lifted two weeks before the last observation (predictive posterior). As a result there is a clear, rapid rebound of the reproduction rate. Comparing with Simulation (b) we do not observe an <em>immediate</em> increase in the number of expected cases and deaths upon lifting lockdown, but there is a significant difference in the number of cases and deaths in the last few days in the plot: Simulation (d) results in both greater number of cases and deaths, as expected. This demonstrates how the effects of lifting an intervention might not become apparent in the measurable variables, e.g.&nbsp;deaths, until several weeks later. The dotted lines correspond to observations, the black bar corresponds to the date of the last observation, and the red bar indicates when <code>lockdown</code> was lifted.</p>
<p>Overall, Simulation (a) shows the prior modelling assumptions, and how these prior assumptions determine the predicted number of cases, etc. before seeing any data. Simulation (b) predicts the trend of the number of cases, etc. using estimated parameters and by keeping all the non-pharmaceutical interventions in place. Simulation (c) shows the estimate in the case where none of the intervention measures are ever put in place. Simulation (d) shows the estimates in the case when the lockdown was lifted two weeks prior to the last observation while keeping all the other non-pharmaceutical interventions in place.</p>
<p>We want to emphasise that we do not provide additional analysis of the Imperial model yet, nor are we aiming to make any claims about the validity or the implications of the model. Instead we refer to Imperial Report 13 for more details and analysis. The purpose of this post is solely to add validation to the <em>inference</em> performed in the paper by obtaining the same results using a different probabilistic programming language (PPL) and by exploring whether or not Turing.jl can be useful for researchers working on these problems.</p>
<p>For our next steps, we’re looking at collaboration with other researchers and further developments of this and similar models. There are some immediate directions to explore:</p>
<ol type="1">
<li>Incorporation of more sources of data, e.g.&nbsp;national mobility, seasonal changes and behavior changes in individuals.</li>
<li>How the assumptions incorporated into the priors and their parameters change resulting posterior.</li>
<li>The current model does not directly include recovery as a possibility and assumes that if a person has been infected once then he/she will be infectious until death. Number of recovered cases suffers from the same issues as the number of cases: it cannot be directly observed. But we can also deal with it in a similar manner as is done with number of cases and incorporate this into the model for a potential improvement. This will result in a plethora of different models from which we can select the most realistic one using different model comparison techniques, e.g.&nbsp;leave-one-out cross-validation (loo-cv).</li>
</ol>
<p>Such model refinement can be potentially valuable given the high impact of this pandemic and the uncertainty and debates in the potential outcomes.</p>
<p><strong>Acknowledgement</strong> <em>We would like to thank the Julia community for creating such an excellent platform for scientific computing, and for the continuous feedback that we have received. We also thank researchers from Computational and Biological Laboratory at Cambridge University for their feedback on an early version of the post.</em> <!----- Footnotes -----></p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Research</category>
  <guid>https://turinglang.org/news/posts/2020-05-04-Imperial-Report13-analysis/</guid>
  <pubDate>Thu, 14 May 2020 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Google Summer of Code/Julia Summer of Code</title>
  <dc:creator>Cameron Pfiffer</dc:creator>
  <link>https://turinglang.org/news/posts/2020-02-12-jsoc/</link>
  <description><![CDATA[ 





<p>Last year, Turing participated in the Google Summer of Code (GSoC) through the Julia language organization. It was a fun time, and the project was better for it. Turing plans to participate in the upcoming GSoC, and we wanted to outline some potential projects and expectations we have for applicants.</p>
<p>If you are not aware, Google provides funds to students around the world to develop a project of their choice over the summer. Students receive funds from Google and spend three months on any open source project.</p>
<p>The Turing development team has prepared a list of possible projects that we have deemed valuable to the project and easy enough that it could feasibly be created in the three-month limit. This list is not exclusive – if you have a good idea, you can write it up in your proposal, though it is recommend that you reach out to any of the Turing team on Julia’s <a href="https://julialang.slack.com/">Slack</a> (you can get an invite <a href="https://slackinvite.julialang.org/">here</a>) or <a href="https://discourse.julialang.org/c/domain/probprog">Discourse</a>. Messages on Discourse should be posted to the “Probabilistic programming” category – we’ll find you!</p>
<p>Possible project ideas:</p>
<ul>
<li><strong>Benchmarking</strong>. Turing’s performance has been sporadically benchmarked against various other probabilistic programming languages (e.g.&nbsp;Turing, Stan, PyMC3, TensorFlow Prob), but a systemic approach to studying where Turing excels and where it falls short would be useful. A GSoC student would implement identical models in many PPLs and build tools to benchmark all PPLs against one another.</li>
<li><strong>Nested sampling integration</strong>. Turing focuses on modularity in inference methods, and the development team would like to see more inference methods, particularly the popular nested sampling method. A Julia package (<a href="https://github.com/mileslucas/NestedSamplers.jl">NestedSamplers.jl</a>) but it is not hooked up to Turing and does not currently have a stable API. A GSoC student would either integrate that package or construct their own nested sampling method and build it into Turing.</li>
<li><strong>Automated function memoization by model annotation</strong>. Function memoization is a way to reduce costly function evaluation by caching the output when the same inputs are given. Turing’s Gibbs sampler often ends up <a href="https://turinglang.org/dev/docs/using-turing/performancetips#reuse-computations-in-gibbs-sampling">rerunning expensive functions</a> multiple times, and it would be a significant performance improvement to allow Turing’s model compiler to automatically memoize functions where appropriate. A student working on this project would become intimately familiar with Turing’s model compiler and build in various automated improvements.</li>
<li><strong>Making Distributions GPU compatible</strong>. Julia’s GPU tooling is generally quite good, but currently Turing is not able to reliably use GPUs while sampling because <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a> is not GPU compatible. A student on this project would work with the Turing developers and the Distributions developers to allow the use of GPU parallelism where possible in Turing.</li>
<li><strong>Static distributions</strong>. Small, fixed-size vectors and matrices are fairly common in Turing models. This means that sampling in Turing can probably benefit from using statically sized vectors and matrices from <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a> instead of the dynamic normal Julia arrays. Beside the often superior performance of small static vectors and matrices, static arrays are also automatically compatible with the GPU stack in Julia. Currently, the main obstacle to using StaticArrays.jl is that distributions in <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a> are not compatible with StaticArrays. A GSoC student would adapt the multivariate and matrix-variate distributions as well as the univariate distribution with vector parameters in Distributions.jl to make a spin-off package called StaticDistributions.jl. The student would then benchmark StaticDistributions.jl against Distributions.jl and showcase an example of using StaticDistributions.jl together with <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays.jl</a> and/or <a href="https://github.com/JuliaGPU/CUDAnative.jl">CUDAnative.jl</a> for GPU-acceleration.</li>
<li><strong>GPnet extensions</strong>. One of Turing’s satellite packages, <a href="https://github.com/TuringLang/GPnet.jl">GPnet</a>, is designed to provide a comprehensive suite of Gaussian process tools. See <a href="https://github.com/TuringLang/GPnet.jl/issues/2">this issue</a> for potential tasks – there’s a lot of interesting stuff going on with GPs, and this task in particular may have some creative freedom to it.</li>
<li><strong>Better chains and model diagnostics</strong>. One package that Turing (and many others) rely on heavily is <a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains.jl</a>, a package designed to format, store, and analyze parameter samples generated during MCMC inference. MCMCChains is currently showing its age a little and has many <a href="https://github.com/TuringLang/MCMCChains.jl/issues/171">bad design choices</a> that need to be fixed. Alternatively, a student could construct a far more lightweight chain system.</li>
<li><strong>Model comparison tools</strong>. Turing and its satellite packages do not currently provide a comprehensive suite of model comparison tools, a critical tool for the applied statistician. A student who worked on this project would implement various model comparison tools like <a href="https://mc-stan.org/loo/">LOO and WAIC</a>, among others.</li>
<li><strong>MLE/MAP tools</strong>. <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum likelihood estimates</a> (MLE) and <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">maximum a posteriori</a> (MAP) estimates can currently only be done by users through a <a href="https://turinglang.org/dev/docs/using-turing/advanced#maximum-a-posteriori-estimation">clunky set of workarounds</a>. A streamlined function like <code>mle(model)</code> or <code>map(model)</code> would be very useful for many of Turing’s users who want to see what the MLE or MAP estimates look like, and it may be valuable to allow for functionality that allows MCMC sampling to begin from the MLE or MAP estimates. Students working on this project will work with optimization packages such as <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> to make MLE and MAP estimation straightforward for Turing models.</li>
<li><strong>Particle sampler improvements</strong>. Turing’s development team has spent a lot of time and energy to make inference methods more modular, but Turing’s particle samplers have not yet been modernized and spun off into a separate package. Two packages that resulted from this were <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC</a> for Hamiltonian MCMC methods, and <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH</a> for Metropolis-Hastings style inference methods. A student who worked on this project would become very familiar with Turing’s inference backend and with particle sampling methods. This is a good project for people who love making things efficient and easily extendable.</li>
</ul>
<p>Other projects are welcome, but we do strongly recommend discussing any potential projects with members of the Turing team, as they will end up mentoring GSoC students for the duration of the project.</p>
<p>We’re looking forward to what people are interested in!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Blog</category>
  <category>GSoC</category>
  <guid>https://turinglang.org/news/posts/2020-02-12-jsoc/</guid>
  <pubDate>Wed, 12 Feb 2020 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Turing’s Blog</title>
  <dc:creator>Cameron Pfiffer</dc:creator>
  <link>https://turinglang.org/news/posts/2019-12-14-initial-post/</link>
  <description><![CDATA[ 





<p>All good open source projects should have a blog, and Turing is one such project. Later on, members of the Turing team may be populating this feed with posts on topics like</p>
<ul>
<li>Interesting things you can do with Turing, or interesting things we have seen others do.</li>
<li>Development updates and major release announcements.</li>
<li>Research updates.</li>
<li>Explorations of Turing’s internals.</li>
<li>Updates to Turing’s satellite projects <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a> or <a href="https://github.com/TuringLang/Bijectors.jl">Bijectors.jl</a>.</li>
</ul>
<p>Stay tuned!</p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Blog</category>
  <guid>https://turinglang.org/news/posts/2019-12-14-initial-post/</guid>
  <pubDate>Sat, 14 Dec 2019 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
