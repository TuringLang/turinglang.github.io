---
title: Turing.jl Newsletter 1
description: The fortnightly newsletter for the Turing.jl probabilistic programming language
categories:
  - Newsletter
author:
  - name: The TuringLang team
    url: /team/
date: 2025-02-28
---

Welcome to the inaugural issue of the Turing.jl newsletter!

**What is this?!**

Hi everyone!
We (the Turing.jl team) are starting a fortnightly series of updates on what we've been up to and what's in the works.
We hope that this will provide you (our users) with some insight into the direction of the Turing ecosystem, and we'd also love for you to chip in with your thoughts if you have any.

You can keep up with the newsletter either on this website, on the [#turing channel in Julia Slack](https://julialang.slack.com/archives/CCYDC34A0), or by subscribing to [our issue on GitHub](https://github.com/TuringLang/Turing.jl/issues/2498).
We might post to other places too (like Discourse), this is still in the works!

**New Turing behaviour, especially `.~`**

Recently we have been focused on reworking a number of internal data structures in DynamicPPL.jl (this is the package that allows you to define models). We haven't released this yet but you might be interested to see [the changelog on GitHub](https://github.com/TuringLang/DynamicPPL.jl/blob/e6a42dd6b410d4ed60d853222c297a391cffe6d1/HISTORY.md).
The main user-facing changes here are the simplification of broadcasted tilde `.~` , which we previously [posted about on Slack here](https://julialang.slack.com/archives/CCYDC34A0/p1738580415136749). We also fixed a bug where the prefixes of nested submodels were applied in the wrong order.

**DifferentiationInterface migration**

From a developer perspective, we have now fully switched over to DifferentiationInterface.jl for automatic differentiation of models occurs. This work of course couldn't have been possible without @gdalle's work on DI itself and also his help with integrating it into DynamicPPL. This also paves the way for a long-standing goal of Turing, which is to expose a series of AD testing utilities that will allow AD package developers to test against a fixed set of models â€” this will allow us to formalise the idea of Turing being 'compatible' with a given AD package.

**The plan for submodels**

We have been discussing for a while now about how best to fully implement submodels (i.e. be able to treat submodels like distributions in the sense that we can sample from them, and also condition models on values obtained from submodels). There is currently a proposal which we've [written up on GitHub](https://github.com/TuringLang/Turing.jl/issues/2485), and goes into more depth about what we'd like to see and the underlying syntax. If this is a Turing feature that you use, do feel free to let us know what you think.

**Turing.jl is now published (again!)**

We recently published a new paper with a high-level overview of Turing.jl's features and implementation. Check it out!  
Fjelde, T. E., Xu, K., Widmann, D., Tarek, M., Pfiffer, C., Trapp, M., Axen, S. D., Sun, X., Hauru, M., Yong, P., Tebbutt, W., Ghahramani, Z., & Ge, H. (2024). Turing.jl: A General-Purpose Probabilistic Programming Language. _ACM Transactions on Probabilistic Machine Learning_, 1(1). ([link](https://dl.acm.org/doi/10.1145/3711897))

We have also published in the conference proceedings of the workshop on Languages for Inference (LAFI), which was held as part of POPL 2025:  
Tim Hargreaves, Qing Li, Charles Knipp, Frederic Wantiez, Simon J. Godsill, Hong Ge.  State Space Model Programming in Turing.jl.  _The Languages for Inference (LAFI) workshop_, 2025. ([link](https://popl25.sigplan.org/details/lafi-2025/11/State-Space-Model-Programming-in-Turing-jl))

**Looking for Google Summer of Code students**

We are keen to take students for [GSoC in 2025](https://julialang.org/jsoc/gsoc/turing/)! If you are interested in working on a Python/R interface to [JuliaBUGS](https://github.com/TuringLang/JuliaBUGS.jl), or making some improvements to [TuringPosteriorDB](https://github.com/JasonPekos/TuringPosteriorDB.jl), do get in touch.
